{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3677980b-6ef3-4318-97a4-a3fd9664c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: pika\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip show pika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae29ca6-75de-4125-aadb-a43874abc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/local/home/hfurquan/myProjects/Leaderboard/cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/local/home/hfurquan/myProjects/Leaderboard/cache\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6768d9c6-da34-45c5-8f37-fae385cc968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/hfurquan/myProjects/govdocs-api/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/local/home/hfurquan/myProjects/govdocs-api/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from docling_core.types.doc import DoclingDocument\n",
    "from docling_core.types.doc.document import DocTagsDocument\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "from pathlib import Path\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"ds4sd/SmolDocling-256M-preview\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"ds4sd/SmolDocling-256M-preview\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(DEVICE)\n",
    "# ,_attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    "# Create input messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6a9a11-7e7a-41ce-8f98-56744857fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doctag><page_header><loc_226><loc_16><loc_249><loc_22>- 7-</page_header>\n",
      "<otsl><loc_12><loc_55><loc_476><loc_263><ecel><ched>1966<lcel><nl><ecel><ched>Tonnage  made(1)  tonnage  shipped<lcel><nl><fcel>Steel ingots (both carbon and alloy) (including  continuous cast steel):<ecel><ecel><nl><fcel>Basic open hearth ...................................... Electric .............................................. Oxygen ...................................................... Total steel ingots ...................................... Continuous cast steel included in above .......................... Alloy steel ingots included in above .......................... Steel castings (both carbon and alloy): Basic open hearth ...................................... Electric .............................................. Other ...................................................... Total steel castings ...................................... Alloy steel castings included in above: High alloy, except manganese and abrasion  resistant .............................................. High alloy, manganese and abrasion resistant ...................... All other alloys .............................................. Total alloy castings ...................................... (1) Includes amounts for sale and for own use. (3) Confidential. (2) Included with \"Basic open hearth\" . Note: High alloy castings include all castings with an alloy content of 8% and over.<ecel><nl><fcel>Total alloy castings ...................................... (1) Includes amounts for sale and for own use. (3) Confidential. (2) Included with \"Basic open hearth\" . Note: High alloy castings include all castings with an alloy content of 8% and over.<ecel><ecel><nl><fcel>(1) Includes amounts for sale and for own use. (3) Confidential. (2) Included with \"Basic open hearth\" . Note: High alloy castings include all castings with an alloy content of 8% and over.<ecel><ecel><nl><fcel>(1) (a) Compiled by principal consuming industries, according to the Steel Distribution Index revised<ecel><ecel><nl><fcel>1966<ecel><ecel><nl><fcel>9,176<ecel><ecel><nl><fcel>Total ..............................................................<ecel><ecel><nl><fcel>9,176<ecel><ecel><nl><fcel>Total ..............................................................<ecel><ecel><nl><fcel>1964, copies of which are available on request.<ecel><ecel><nl><fcel>(b) Includes producers' own-make castings allocated to appropriate consuming industry.<ecel><ecel><nl></otsl>\n",
      "</doctag><end_of_utterance>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_filoutput_path_htmle_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# export as any format\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# HTML\u001b[39;00m\n\u001b[32m     36\u001b[39m output_path_html = Path(\u001b[33m\"\u001b[39m\u001b[33mOut/\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[33m\"\u001b[39m\u001b[33mexample.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m doc.save_as_html(\u001b[43moutput_filoutput_path_htmle_path\u001b[49m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# MD\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(doc.export_to_markdown())\n",
      "\u001b[31mNameError\u001b[39m: name 'output_filoutput_path_htmle_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "image = load_image(\"example.jpg\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Convert this page to docling.\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=8192)\n",
    "prompt_length = inputs.input_ids.shape[1]\n",
    "trimmed_generated_ids = generated_ids[:, prompt_length:]\n",
    "doctags = processor.batch_decode(\n",
    "    trimmed_generated_ids,\n",
    "    skip_special_tokens=False,\n",
    ")[0].lstrip()\n",
    "\n",
    "# Populate document\n",
    "doctags_doc = DocTagsDocument.from_doctags_and_image_pairs([doctags], [image])\n",
    "print(doctags)\n",
    "# create a docling document\n",
    "doc = DoclingDocument(name=\"Document\")\n",
    "doc.load_from_doctags(doctags_doc)\n",
    "\n",
    "# export as any format\n",
    "# HTML\n",
    "output_path_html = Path(\"Out/\") / \"example.html\"\n",
    "doc.save_as_html(output_filoutput_path_htmle_path)\n",
    "# MD\n",
    "print(doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d74bef-f593-4284-83c9-814dc5737630",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_html = Path(\"Out/\") / \"example.html\"\n",
    "doc.save_as_html(output_path_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac82f2-5576-482d-bc1e-f189c6b96036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "govdocs-api jupyter kernel",
   "language": "python",
   "name": "govdocs-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
