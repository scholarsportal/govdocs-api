2025-03-20 15:30:23,866 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 15:30:24,894 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 15:30:25,925 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 15:30:26,953 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 15:30:27,977 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 15:30:29,025 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 15:30:30,073 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 15:30:31,103 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 15:30:32,129 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 15:30:33,166 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 15:30:34,190 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 15:30:35,219 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 15:30:36,245 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 15:30:37,273 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 15:30:38,299 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 15:30:39,333 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 15:30:40,363 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 15:30:41,392 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 15:30:42,417 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 15:30:43,449 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 15:30:44,480 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 15:30:45,506 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 15:30:46,533 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 15:30:47,567 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 15:30:48,613 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 15:30:49,658 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 15:30:50,686 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 15:30:51,713 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 15:30:52,739 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 15:30:53,767 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 15:30:54,793 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 15:30:55,820 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 15:30:56,855 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 15:30:57,882 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 15:30:58,914 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 15:30:59,942 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 15:31:00,967 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 15:31:01,994 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 15:31:03,026 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 15:31:04,057 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 15:31:05,092 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 15:31:06,126 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 15:31:07,155 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 15:31:08,181 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 15:31:09,207 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 15:31:10,237 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 15:31:11,262 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 15:31:12,287 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 15:31:13,318 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 15:31:14,350 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 15:31:15,376 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 15:31:16,403 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 15:31:17,433 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 15:31:18,457 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 15:31:19,483 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 15:31:20,510 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 15:31:21,535 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 15:31:22,566 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 15:31:23,592 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 15:31:24,617 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 15:31:25,645 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 15:31:26,700 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 15:31:27,749 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 15:31:28,795 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 15:31:29,820 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 15:31:30,850 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 15:31:31,878 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 15:31:32,910 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 15:31:33,939 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 15:31:34,965 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 15:31:35,995 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 15:31:37,023 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 15:31:38,051 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 15:31:39,086 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 15:31:40,124 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 15:31:41,163 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 15:31:42,189 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 15:31:43,219 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 15:31:44,244 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 15:31:45,271 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 15:31:46,300 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 15:31:47,335 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 15:31:48,365 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 15:31:49,398 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 15:31:50,425 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 15:31:51,449 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 15:31:52,481 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 15:31:53,506 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 15:31:54,539 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 15:31:55,570 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 15:31:56,601 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 15:31:57,629 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 15:31:58,659 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 15:31:59,689 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 15:32:00,717 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 15:32:01,743 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 15:32:02,790 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 15:32:03,839 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 15:32:04,887 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 15:32:05,938 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 15:32:06,968 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 15:32:08,000 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 15:32:09,025 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 15:32:10,051 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 15:32:11,077 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 15:32:12,103 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 15:32:13,129 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 15:32:14,168 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 15:32:15,200 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 15:32:16,231 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 15:32:17,263 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 15:32:18,290 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 15:32:19,336 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 15:32:20,381 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 15:32:21,406 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 15:32:22,431 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 15:32:23,461 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 15:32:24,489 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 15:32:25,520 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 15:32:26,552 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 15:32:27,586 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 15:32:28,621 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 15:32:29,649 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 15:32:30,678 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 15:32:31,708 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 15:32:32,736 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 15:32:33,760 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 15:32:34,785 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 15:32:35,811 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 15:32:36,840 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 15:32:37,872 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 15:32:38,900 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 15:32:39,929 - olm-ocr-api - WARNING - Attempt 133: Please wait for sglang server to become ready...
2025-03-20 15:32:40,956 - olm-ocr-api - WARNING - Attempt 134: Please wait for sglang server to become ready...
2025-03-20 15:32:41,987 - olm-ocr-api - WARNING - Attempt 135: Please wait for sglang server to become ready...
2025-03-20 15:32:43,013 - olm-ocr-api - WARNING - Attempt 136: Please wait for sglang server to become ready...
2025-03-20 15:32:44,061 - olm-ocr-api - WARNING - Attempt 137: Please wait for sglang server to become ready...
2025-03-20 15:32:45,089 - olm-ocr-api - WARNING - Attempt 138: Please wait for sglang server to become ready...
2025-03-20 15:32:46,121 - olm-ocr-api - WARNING - Attempt 139: Please wait for sglang server to become ready...
2025-03-20 15:32:47,147 - olm-ocr-api - WARNING - Attempt 140: Please wait for sglang server to become ready...
2025-03-20 15:32:48,172 - olm-ocr-api - WARNING - Attempt 141: Please wait for sglang server to become ready...
2025-03-20 15:32:49,201 - olm-ocr-api - WARNING - Attempt 142: Please wait for sglang server to become ready...
2025-03-20 15:32:50,229 - olm-ocr-api - WARNING - Attempt 143: Please wait for sglang server to become ready...
2025-03-20 15:32:51,256 - olm-ocr-api - WARNING - Attempt 144: Please wait for sglang server to become ready...
2025-03-20 15:32:52,289 - olm-ocr-api - WARNING - Attempt 145: Please wait for sglang server to become ready...
2025-03-20 15:32:53,315 - olm-ocr-api - WARNING - Attempt 146: Please wait for sglang server to become ready...
2025-03-20 15:32:54,347 - olm-ocr-api - WARNING - Attempt 147: Please wait for sglang server to become ready...
2025-03-20 15:32:55,373 - olm-ocr-api - WARNING - Attempt 148: Please wait for sglang server to become ready...
2025-03-20 15:32:56,403 - olm-ocr-api - WARNING - Attempt 149: Please wait for sglang server to become ready...
2025-03-20 15:32:57,430 - olm-ocr-api - WARNING - Attempt 150: Please wait for sglang server to become ready...
2025-03-20 15:32:58,461 - olm-ocr-api - WARNING - Attempt 151: Please wait for sglang server to become ready...
2025-03-20 15:32:59,486 - olm-ocr-api - WARNING - Attempt 152: Please wait for sglang server to become ready...
2025-03-20 15:33:00,512 - olm-ocr-api - WARNING - Attempt 153: Please wait for sglang server to become ready...
2025-03-20 15:33:01,537 - olm-ocr-api - WARNING - Attempt 154: Please wait for sglang server to become ready...
2025-03-20 15:33:02,563 - olm-ocr-api - WARNING - Attempt 155: Please wait for sglang server to become ready...
2025-03-20 15:33:03,598 - olm-ocr-api - WARNING - Attempt 156: Please wait for sglang server to become ready...
2025-03-20 15:33:04,627 - olm-ocr-api - WARNING - Attempt 157: Please wait for sglang server to become ready...
2025-03-20 15:33:05,654 - olm-ocr-api - WARNING - Attempt 158: Please wait for sglang server to become ready...
2025-03-20 15:33:06,686 - olm-ocr-api - WARNING - Attempt 159: Please wait for sglang server to become ready...
2025-03-20 15:33:07,718 - olm-ocr-api - WARNING - Attempt 160: Please wait for sglang server to become ready...
2025-03-20 15:33:08,751 - olm-ocr-api - WARNING - Attempt 161: Please wait for sglang server to become ready...
2025-03-20 15:33:09,782 - olm-ocr-api - WARNING - Attempt 162: Please wait for sglang server to become ready...
2025-03-20 15:33:10,811 - olm-ocr-api - WARNING - Attempt 163: Please wait for sglang server to become ready...
2025-03-20 15:33:11,839 - olm-ocr-api - WARNING - Attempt 164: Please wait for sglang server to become ready...
2025-03-20 15:33:12,868 - olm-ocr-api - WARNING - Attempt 165: Please wait for sglang server to become ready...
2025-03-20 15:33:13,894 - olm-ocr-api - WARNING - Attempt 166: Please wait for sglang server to become ready...
2025-03-20 15:33:14,922 - olm-ocr-api - WARNING - Attempt 167: Please wait for sglang server to become ready...
2025-03-20 15:33:15,949 - olm-ocr-api - WARNING - Attempt 168: Please wait for sglang server to become ready...
2025-03-20 15:33:16,977 - olm-ocr-api - WARNING - Attempt 169: Please wait for sglang server to become ready...
2025-03-20 15:33:18,003 - olm-ocr-api - WARNING - Attempt 170: Please wait for sglang server to become ready...
2025-03-20 15:33:19,036 - olm-ocr-api - WARNING - Attempt 171: Please wait for sglang server to become ready...
2025-03-20 15:33:20,061 - olm-ocr-api - WARNING - Attempt 172: Please wait for sglang server to become ready...
2025-03-20 15:33:21,093 - olm-ocr-api - WARNING - Attempt 173: Please wait for sglang server to become ready...
2025-03-20 15:33:22,119 - olm-ocr-api - WARNING - Attempt 174: Please wait for sglang server to become ready...
2025-03-20 15:33:23,146 - olm-ocr-api - WARNING - Attempt 175: Please wait for sglang server to become ready...
2025-03-20 15:33:24,182 - olm-ocr-api - WARNING - Attempt 176: Please wait for sglang server to become ready...
2025-03-20 15:33:25,207 - olm-ocr-api - WARNING - Attempt 177: Please wait for sglang server to become ready...
2025-03-20 15:33:26,236 - olm-ocr-api - WARNING - Attempt 178: Please wait for sglang server to become ready...
2025-03-20 15:33:27,264 - olm-ocr-api - WARNING - Attempt 179: Please wait for sglang server to become ready...
2025-03-20 15:33:28,296 - olm-ocr-api - WARNING - Attempt 180: Please wait for sglang server to become ready...
2025-03-20 15:33:29,323 - olm-ocr-api - WARNING - Attempt 181: Please wait for sglang server to become ready...
2025-03-20 15:33:30,355 - olm-ocr-api - WARNING - Attempt 182: Please wait for sglang server to become ready...
2025-03-20 15:33:31,383 - olm-ocr-api - WARNING - Attempt 183: Please wait for sglang server to become ready...
2025-03-20 15:33:32,410 - olm-ocr-api - WARNING - Attempt 184: Please wait for sglang server to become ready...
2025-03-20 15:33:33,439 - olm-ocr-api - WARNING - Attempt 185: Please wait for sglang server to become ready...
2025-03-20 15:33:34,481 - olm-ocr-api - WARNING - Attempt 186: Please wait for sglang server to become ready...
2025-03-20 15:33:35,509 - olm-ocr-api - WARNING - Attempt 187: Please wait for sglang server to become ready...
2025-03-20 15:33:36,541 - olm-ocr-api - WARNING - Attempt 188: Please wait for sglang server to become ready...
2025-03-20 15:33:37,595 - olm-ocr-api - WARNING - Attempt 189: Please wait for sglang server to become ready...
2025-03-20 15:33:38,645 - olm-ocr-api - WARNING - Attempt 190: Please wait for sglang server to become ready...
2025-03-20 15:33:39,693 - olm-ocr-api - WARNING - Attempt 191: Please wait for sglang server to become ready...
2025-03-20 15:33:40,742 - olm-ocr-api - WARNING - Attempt 192: Please wait for sglang server to become ready...
2025-03-20 15:33:41,766 - olm-ocr-api - WARNING - Attempt 193: Please wait for sglang server to become ready...
2025-03-20 15:33:42,791 - olm-ocr-api - WARNING - Attempt 194: Please wait for sglang server to become ready...
2025-03-20 15:33:43,820 - olm-ocr-api - WARNING - Attempt 195: Please wait for sglang server to become ready...
2025-03-20 15:33:44,850 - olm-ocr-api - WARNING - Attempt 196: Please wait for sglang server to become ready...
2025-03-20 15:33:45,881 - olm-ocr-api - WARNING - Attempt 197: Please wait for sglang server to become ready...
2025-03-20 15:33:46,906 - olm-ocr-api - WARNING - Attempt 198: Please wait for sglang server to become ready...
2025-03-20 15:33:47,938 - olm-ocr-api - WARNING - Attempt 199: Please wait for sglang server to become ready...
2025-03-20 15:33:48,966 - olm-ocr-api - WARNING - Attempt 200: Please wait for sglang server to become ready...
2025-03-20 15:33:49,992 - olm-ocr-api - WARNING - Attempt 201: Please wait for sglang server to become ready...
2025-03-20 15:33:51,018 - olm-ocr-api - WARNING - Attempt 202: Please wait for sglang server to become ready...
2025-03-20 15:33:52,062 - olm-ocr-api - WARNING - Attempt 203: Please wait for sglang server to become ready...
2025-03-20 15:33:53,095 - olm-ocr-api - WARNING - Attempt 204: Please wait for sglang server to become ready...
2025-03-20 15:33:54,121 - olm-ocr-api - WARNING - Attempt 205: Please wait for sglang server to become ready...
2025-03-20 15:33:55,153 - olm-ocr-api - WARNING - Attempt 206: Please wait for sglang server to become ready...
2025-03-20 15:33:56,185 - olm-ocr-api - WARNING - Attempt 207: Please wait for sglang server to become ready...
2025-03-20 15:33:57,211 - olm-ocr-api - WARNING - Attempt 208: Please wait for sglang server to become ready...
2025-03-20 15:33:58,236 - olm-ocr-api - WARNING - Attempt 209: Please wait for sglang server to become ready...
2025-03-20 15:33:59,263 - olm-ocr-api - WARNING - Attempt 210: Please wait for sglang server to become ready...
2025-03-20 15:34:00,291 - olm-ocr-api - WARNING - Attempt 211: Please wait for sglang server to become ready...
2025-03-20 15:34:01,330 - olm-ocr-api - WARNING - Attempt 212: Please wait for sglang server to become ready...
2025-03-20 15:34:02,357 - olm-ocr-api - WARNING - Attempt 213: Please wait for sglang server to become ready...
2025-03-20 15:34:03,388 - olm-ocr-api - WARNING - Attempt 214: Please wait for sglang server to become ready...
2025-03-20 15:34:04,417 - olm-ocr-api - WARNING - Attempt 215: Please wait for sglang server to become ready...
2025-03-20 15:34:05,449 - olm-ocr-api - WARNING - Attempt 216: Please wait for sglang server to become ready...
2025-03-20 15:34:06,478 - olm-ocr-api - WARNING - Attempt 217: Please wait for sglang server to become ready...
2025-03-20 15:34:07,524 - olm-ocr-api - WARNING - Attempt 218: Please wait for sglang server to become ready...
2025-03-20 15:34:08,556 - olm-ocr-api - WARNING - Attempt 219: Please wait for sglang server to become ready...
2025-03-20 15:34:09,583 - olm-ocr-api - WARNING - Attempt 220: Please wait for sglang server to become ready...
2025-03-20 15:34:10,613 - olm-ocr-api - WARNING - Attempt 221: Please wait for sglang server to become ready...
2025-03-20 15:34:11,647 - olm-ocr-api - WARNING - Attempt 222: Please wait for sglang server to become ready...
2025-03-20 15:34:12,677 - olm-ocr-api - WARNING - Attempt 223: Please wait for sglang server to become ready...
2025-03-20 15:34:13,713 - olm-ocr-api - WARNING - Attempt 224: Please wait for sglang server to become ready...
2025-03-20 15:34:14,744 - olm-ocr-api - WARNING - Attempt 225: Please wait for sglang server to become ready...
2025-03-20 15:34:15,773 - olm-ocr-api - WARNING - Attempt 226: Please wait for sglang server to become ready...
2025-03-20 15:34:16,805 - olm-ocr-api - WARNING - Attempt 227: Please wait for sglang server to become ready...
2025-03-20 15:34:17,833 - olm-ocr-api - WARNING - Attempt 228: Please wait for sglang server to become ready...
2025-03-20 15:34:18,860 - olm-ocr-api - WARNING - Attempt 229: Please wait for sglang server to become ready...
2025-03-20 15:34:19,888 - olm-ocr-api - WARNING - Attempt 230: Please wait for sglang server to become ready...
2025-03-20 15:34:20,941 - olm-ocr-api - WARNING - Attempt 231: Please wait for sglang server to become ready...
2025-03-20 15:34:21,991 - olm-ocr-api - WARNING - Attempt 232: Please wait for sglang server to become ready...
2025-03-20 15:34:23,016 - olm-ocr-api - WARNING - Attempt 233: Please wait for sglang server to become ready...
2025-03-20 15:34:24,045 - olm-ocr-api - WARNING - Attempt 234: Please wait for sglang server to become ready...
2025-03-20 15:34:25,098 - olm-ocr-api - WARNING - Attempt 235: Please wait for sglang server to become ready...
2025-03-20 15:34:26,139 - olm-ocr-api - WARNING - Attempt 236: Please wait for sglang server to become ready...
2025-03-20 15:34:27,164 - olm-ocr-api - WARNING - Attempt 237: Please wait for sglang server to become ready...
2025-03-20 15:34:28,199 - olm-ocr-api - WARNING - Attempt 238: Please wait for sglang server to become ready...
2025-03-20 15:34:29,229 - olm-ocr-api - WARNING - Attempt 239: Please wait for sglang server to become ready...
2025-03-20 15:34:30,262 - olm-ocr-api - WARNING - Attempt 240: Please wait for sglang server to become ready...
2025-03-20 15:34:31,294 - olm-ocr-api - WARNING - Attempt 241: Please wait for sglang server to become ready...
2025-03-20 15:34:32,322 - olm-ocr-api - WARNING - Attempt 242: Please wait for sglang server to become ready...
2025-03-20 15:34:33,349 - olm-ocr-api - WARNING - Attempt 243: Please wait for sglang server to become ready...
2025-03-20 15:34:34,381 - olm-ocr-api - WARNING - Attempt 244: Please wait for sglang server to become ready...
2025-03-20 15:34:35,411 - olm-ocr-api - WARNING - Attempt 245: Please wait for sglang server to become ready...
2025-03-20 15:34:36,465 - olm-ocr-api - WARNING - Attempt 246: Please wait for sglang server to become ready...
2025-03-20 15:34:37,490 - olm-ocr-api - WARNING - Attempt 247: Please wait for sglang server to become ready...
2025-03-20 15:34:38,518 - olm-ocr-api - WARNING - Attempt 248: Please wait for sglang server to become ready...
2025-03-20 15:34:39,551 - olm-ocr-api - WARNING - Attempt 249: Please wait for sglang server to become ready...
2025-03-20 15:34:40,580 - olm-ocr-api - WARNING - Attempt 250: Please wait for sglang server to become ready...
2025-03-20 15:34:41,610 - olm-ocr-api - WARNING - Attempt 251: Please wait for sglang server to become ready...
2025-03-20 15:36:39,377 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:39,377 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,501 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:41,502 - olm-ocr-api - WARNING - Got name 'sglang_logger' is not defined when reading log line from inference server, skipping
2025-03-20 15:36:42,525 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 15:36:43,552 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 15:36:44,578 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 15:36:45,609 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 15:36:46,641 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 15:36:47,676 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 15:36:48,706 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 15:36:49,734 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 15:36:50,760 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 15:36:51,813 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 15:36:52,837 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 15:36:53,865 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 15:36:54,891 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 15:36:55,922 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 15:36:56,974 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 15:36:58,007 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 15:36:59,037 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 15:37:00,063 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 15:37:01,093 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 15:37:02,118 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 15:37:03,143 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 15:37:04,173 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 15:37:05,228 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 15:37:06,261 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 15:37:07,291 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 15:37:08,320 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 15:37:09,354 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 15:37:10,386 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 15:37:11,418 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 15:37:12,444 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 15:37:13,474 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 15:37:14,500 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 15:37:15,529 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 15:37:16,557 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 15:37:17,590 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 15:37:18,627 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 15:37:19,662 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 15:37:20,691 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 15:37:21,726 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 15:37:22,755 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 15:37:23,781 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 15:37:24,811 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 15:37:25,838 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 15:37:26,866 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 15:37:27,896 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 15:37:28,949 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 15:40:07,597 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 15:40:07,597 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:07,597 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 15:40:07,602 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO -   File "<frozen runpy>", line 198, in _run_module_as_main
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO -   File "<frozen runpy>", line 88, in _run_code
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/launch_server.py", line 6, in <module>
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO -     from sglang.srt.entrypoints.http_server import launch_server
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,691 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/entrypoints/http_server.py", line 41, in <module>
2025-03-20 15:40:09,691 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.entrypoints.engine import _launch_subprocesses
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/entrypoints/engine.py", line 36, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.managers.data_parallel_controller import (
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/data_parallel_controller.py", line 27, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.managers.io_struct import (
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/io_struct.py", line 24, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.managers.schedule_batch import BaseFinishReason
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/schedule_batch.py", line 42, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.configs.model_config import ModelConfig
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/configs/model_config.py", line 24, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from sglang.srt.layers.quantization import QUANTIZATION_METHODS
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/quantization/__init__.py", line 5, in <module>
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO -     from vllm.model_executor.layers.quantization.aqlm import AQLMConfig
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:09,692 - olm-ocr-api - INFO - ModuleNotFoundError: No module named 'vllm'
2025-03-20 15:40:09,692 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 15:40:10,862 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 15:40:11,895 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 15:40:12,922 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 15:40:13,954 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 15:40:14,984 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:06:02,946 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:06:02,946 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:02,947 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:06:02,947 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:05,694 - olm-ocr-api - INFO - INFO 03-20 16:06:05 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:06:05,694 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,703 - olm-ocr-api - INFO - [2025-03-20 16:06:10] server_args=ServerArgs(model_path='/local/home/hfurquan/myProjects/Leaderboard/cache/models--allenai--olmOCR-7B-0225-preview', tokenizer_path='/local/home/hfurquan/myProjects/Leaderboard/cache/models--allenai--olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='/local/home/hfurquan/myProjects/Leaderboard/cache/models--allenai--olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=523165857, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=2, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:06:10,703 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -   File "<frozen runpy>", line 198, in _run_module_as_main
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -   File "<frozen runpy>", line 88, in _run_code
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/launch_server.py", line 14, in <module>
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -     launch_server(server_args)
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/entrypoints/http_server.py", line 619, in launch_server
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -     tokenizer_manager, scheduler_info = _launch_subprocesses(server_args=server_args)
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,730 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/entrypoints/engine.py", line 499, in _launch_subprocesses
2025-03-20 16:06:10,730 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -     tokenizer_manager = TokenizerManager(server_args, port_args)
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tokenizer_manager.py", line 155, in __init__
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -     self.model_config = ModelConfig(
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/configs/model_config.py", line 59, in __init__
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -     self.hf_config = get_config(
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -                      ^^^^^^^^^^^
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/hf_transformers_utils.py", line 73, in get_config
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -     config = AutoConfig.from_pretrained(
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1091, in from_pretrained
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO -     raise ValueError(
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:10,731 - olm-ocr-api - INFO - ValueError: Unrecognized model in /local/home/hfurquan/myProjects/Leaderboard/cache/models--allenai--olmOCR-7B-0225-preview. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth, chatglm, exaone, qwen2_5_vl, multi_modality
2025-03-20 16:06:10,731 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:06:12,599 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:06:13,634 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:06:14,676 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:06:15,705 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:06:16,738 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:06:17,773 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:06:18,800 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:06:19,826 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:06:20,853 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:06:21,881 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:06:22,910 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:06:23,946 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:06:24,985 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:06:26,017 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:06:27,042 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:06:28,068 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:06:29,095 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:08:00,400 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:08:00,400 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:00,400 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:08:00,400 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:03,045 - olm-ocr-api - INFO - INFO 03-20 16:08:03 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:08:03,045 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:05,916 - olm-ocr-api - INFO - [2025-03-20 16:08:05] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=506111571, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=2, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:08:05,916 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:08,919 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:08:08,919 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:08,919 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:08:08,919 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:09,054 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:08:09,054 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:09,054 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:08:09,054 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:11,772 - olm-ocr-api - INFO - INFO 03-20 16:08:11 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:08:11,772 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:11,783 - olm-ocr-api - INFO - INFO 03-20 16:08:11 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:08:11,784 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:17,083 - olm-ocr-api - INFO - [2025-03-20 16:08:17 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:08:17,083 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:17,835 - olm-ocr-api - INFO - [2025-03-20 16:08:17] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:08:17,835 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,556 - olm-ocr-api - INFO - [2025-03-20 16:08:23 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:08:23,556 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,556 - olm-ocr-api - INFO - [2025-03-20 16:08:23 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:08:23,556 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,556 - olm-ocr-api - INFO - [2025-03-20 16:08:23 TP0] Init torch distributed begin.
2025-03-20 16:08:23,556 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO - [2025-03-20 16:08:23 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,562 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:08:23,562 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 163, in __init__
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -     min_per_gpu_memory = self.init_torch_distributed()
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 268, in init_torch_distributed
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -     torch.get_device_module(self.device).set_device(self.gpu_id)
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/cuda/__init__.py", line 478, in set_device
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO -     torch._C._cuda_setDevice(device)
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - RuntimeError: CUDA error: invalid device ordinal
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - For debugging consider passing CUDA_LAUNCH_BLOCKING=1
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - 
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,563 - olm-ocr-api - INFO - 
2025-03-20 16:08:23,563 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,564 - olm-ocr-api - INFO - [2025-03-20 16:08:23] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:08:23,564 - olm-ocr-api - WARNING - Got name 're' is not defined when reading log line from inference server, skipping
2025-03-20 16:08:23,730 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:08:24,762 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:08:25,795 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:08:26,821 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:08:27,846 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:08:28,877 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:08:29,905 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:08:30,936 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:08:31,962 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:08:32,990 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:08:34,018 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:08:35,047 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:08:36,081 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:08:37,105 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:08:38,138 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:08:39,167 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:08:40,202 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:08:41,253 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:08:42,278 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:08:43,311 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:08:44,337 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:08:45,365 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:08:46,412 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:08:47,457 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:08:48,511 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:08:49,539 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:08:50,566 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:08:51,597 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 16:08:52,624 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 16:08:53,650 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 16:08:54,677 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 16:08:55,701 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 16:08:56,730 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 16:08:57,761 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 16:08:58,789 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 16:08:59,843 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 16:09:00,871 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 16:09:01,905 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 16:09:02,934 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 16:09:03,960 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 16:09:05,014 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 16:09:06,058 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 16:12:33,778 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:12:33,779 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:12:36,072 - olm-ocr-api - INFO - INFO 03-20 16:12:36 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:12:39,142 - olm-ocr-api - INFO - [2025-03-20 16:12:39] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=1044114695, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:12:40,473 - olm-ocr-api - INFO - [2025-03-20 16:12:40] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:12:42,246 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:12:42,246 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:12:42,459 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:12:42,459 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:12:44,604 - olm-ocr-api - INFO - INFO 03-20 16:12:44 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:12:44,848 - olm-ocr-api - INFO - INFO 03-20 16:12:44 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:12:49,303 - olm-ocr-api - INFO - [2025-03-20 16:12:49 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:12:49,340 - olm-ocr-api - INFO - [2025-03-20 16:12:49 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:12:49,340 - olm-ocr-api - INFO - [2025-03-20 16:12:49 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:12:49,340 - olm-ocr-api - INFO - [2025-03-20 16:12:49 TP0] Init torch distributed begin.
2025-03-20 16:12:50,492 - olm-ocr-api - INFO - [2025-03-20 16:12:50 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 16:12:50,492 - olm-ocr-api - INFO - [2025-03-20 16:12:50 TP0] Load weight begin. avail mem=30.15 GB
2025-03-20 16:12:50,614 - olm-ocr-api - INFO - [2025-03-20 16:12:50 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 16:12:51,003 - olm-ocr-api - INFO - [2025-03-20 16:12:51 TP0] Using model weights format ['*.safetensors']
2025-03-20 16:12:51,085 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 16:12:56,993 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.91s/it]
2025-03-20 16:13:03,321 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:12<00:12,  6.15s/it]
2025-03-20 16:13:09,547 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:18<00:06,  6.19s/it]
2025-03-20 16:13:11,733 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:20<00:00,  4.61s/it]
2025-03-20 16:13:11,733 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:20<00:00,  5.16s/it]
2025-03-20 16:13:11,733 - olm-ocr-api - INFO - 
2025-03-20 16:13:11,770 - olm-ocr-api - INFO - [2025-03-20 16:13:11 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=14.43 GB, mem usage=15.72 GB.
2025-03-20 16:13:12,415 - olm-ocr-api - INFO - [2025-03-20 16:13:12 TP0] KV Cache is allocated. #tokens: 134657, K size: 3.60 GB, V size: 3.60 GB
2025-03-20 16:13:12,415 - olm-ocr-api - INFO - [2025-03-20 16:13:12 TP0] Memory pool end. avail mem=6.93 GB
2025-03-20 16:13:12,646 - olm-ocr-api - INFO - 2025-03-20 16:13:12,646 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 16:13:12,700 - olm-ocr-api - INFO - [2025-03-20 16:13:12 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.43 GB
2025-03-20 16:13:13,677 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.40 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 16:13:13,677 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 16:13:13,694 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.40 GB):   0%|          | 0/23 [00:00<?, ?it/s]
2025-03-20 16:13:13,698 - olm-ocr-api - INFO - [2025-03-20 16:13:13 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 16:13:13,698 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.capture()
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 16:13:13,699 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 16:13:13,700 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1810, in _write_ninja_file_and_build_library
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -     extra_ldflags = _prepare_ldflags(
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -                     ^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1899, in _prepare_ldflags
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -     if (not os.path.exists(_join_cuda_home(extra_lib_dir)) and
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2416, in _join_cuda_home
2025-03-20 16:13:13,701 - olm-ocr-api - INFO -     raise OSError('CUDA_HOME environment variable is not set. '
2025-03-20 16:13:13,701 - olm-ocr-api - INFO - OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.
2025-03-20 16:13:13,701 - olm-ocr-api - INFO - 
2025-03-20 16:13:13,701 - olm-ocr-api - INFO - [2025-03-20 16:13:13] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:13:13,887 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:13:14,915 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:13:15,942 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:13:16,966 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:13:17,997 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:13:19,027 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:13:20,059 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:13:21,087 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:13:22,114 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:13:23,147 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:13:24,178 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:13:25,203 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:13:26,231 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:13:27,259 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:13:28,285 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:13:29,338 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:13:30,363 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:13:31,403 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:13:32,429 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:13:33,466 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:13:34,515 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:13:35,561 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:13:36,596 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:13:37,627 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:13:38,661 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:13:39,686 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:13:40,713 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:13:41,747 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 16:13:42,775 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 16:13:43,803 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 16:13:44,831 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 16:13:45,864 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 16:13:46,891 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 16:13:47,916 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 16:13:48,945 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 16:13:49,972 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 16:13:51,018 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 16:13:52,042 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 16:13:53,072 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 16:13:54,104 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 16:13:55,156 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 16:13:56,185 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 16:13:57,234 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 16:13:58,282 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 16:13:59,332 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 16:14:00,360 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 16:14:01,391 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 16:14:02,419 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 16:14:03,444 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 16:14:04,471 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 16:14:05,502 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 16:14:06,534 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 16:14:07,559 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 16:14:08,595 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 16:14:09,621 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 16:14:10,645 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 16:14:11,686 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 16:14:12,714 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 16:14:13,748 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 16:14:14,774 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 16:14:15,806 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 16:14:16,844 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 16:14:17,871 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 16:14:18,903 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 16:14:19,946 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 16:14:20,972 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 16:14:22,001 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 16:14:23,033 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 16:14:24,062 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 16:14:25,094 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 16:14:26,123 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 16:14:27,153 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 16:14:28,180 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 16:14:29,209 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 16:14:30,238 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 16:14:31,285 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 16:14:32,327 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 16:14:33,353 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 16:14:34,381 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 16:14:35,407 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 16:14:36,442 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 16:14:37,477 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 16:14:38,526 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 16:14:39,559 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 16:14:40,587 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 16:14:41,615 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 16:14:42,663 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 16:14:43,691 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 16:14:44,717 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 16:14:45,743 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 16:14:46,775 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 16:14:47,808 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 16:16:08,596 - olm-ocr-api - WARNING - Attempt 252: Please wait for sglang server to become ready...
2025-03-20 16:16:09,624 - olm-ocr-api - WARNING - Attempt 253: Please wait for sglang server to become ready...
2025-03-20 16:16:10,671 - olm-ocr-api - WARNING - Attempt 254: Please wait for sglang server to become ready...
2025-03-20 16:16:11,699 - olm-ocr-api - WARNING - Attempt 255: Please wait for sglang server to become ready...
2025-03-20 16:16:12,725 - olm-ocr-api - WARNING - Attempt 256: Please wait for sglang server to become ready...
2025-03-20 16:16:13,758 - olm-ocr-api - WARNING - Attempt 257: Please wait for sglang server to become ready...
2025-03-20 16:16:14,790 - olm-ocr-api - WARNING - Attempt 258: Please wait for sglang server to become ready...
2025-03-20 16:16:15,285 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 16:16:15,818 - olm-ocr-api - WARNING - Attempt 259: Please wait for sglang server to become ready...
2025-03-20 16:16:16,310 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 16:16:16,845 - olm-ocr-api - WARNING - Attempt 260: Please wait for sglang server to become ready...
2025-03-20 16:16:17,337 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 16:16:17,893 - olm-ocr-api - WARNING - Attempt 261: Please wait for sglang server to become ready...
2025-03-20 16:16:18,366 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 16:16:18,926 - olm-ocr-api - WARNING - Attempt 262: Please wait for sglang server to become ready...
2025-03-20 16:16:19,396 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 16:16:19,960 - olm-ocr-api - WARNING - Attempt 263: Please wait for sglang server to become ready...
2025-03-20 16:16:20,427 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 16:16:20,998 - olm-ocr-api - WARNING - Attempt 264: Please wait for sglang server to become ready...
2025-03-20 16:16:21,178 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:16:21,452 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 16:16:22,023 - olm-ocr-api - WARNING - Attempt 265: Please wait for sglang server to become ready...
2025-03-20 16:16:22,204 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:16:22,484 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 16:16:23,052 - olm-ocr-api - WARNING - Attempt 266: Please wait for sglang server to become ready...
2025-03-20 16:16:23,236 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:16:23,515 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 16:16:24,076 - olm-ocr-api - WARNING - Attempt 267: Please wait for sglang server to become ready...
2025-03-20 16:16:24,263 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:16:24,545 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 16:16:25,107 - olm-ocr-api - WARNING - Attempt 268: Please wait for sglang server to become ready...
2025-03-20 16:16:25,298 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:16:25,575 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 16:16:26,137 - olm-ocr-api - WARNING - Attempt 269: Please wait for sglang server to become ready...
2025-03-20 16:16:26,329 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:16:26,605 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 16:16:27,129 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:16:27,165 - olm-ocr-api - WARNING - Attempt 270: Please wait for sglang server to become ready...
2025-03-20 16:16:27,380 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:16:27,639 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 16:16:28,158 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:16:28,200 - olm-ocr-api - WARNING - Attempt 271: Please wait for sglang server to become ready...
2025-03-20 16:16:28,408 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:16:28,668 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 16:16:29,188 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:16:29,235 - olm-ocr-api - WARNING - Attempt 272: Please wait for sglang server to become ready...
2025-03-20 16:16:29,457 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:16:29,697 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 16:16:30,225 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:16:30,262 - olm-ocr-api - WARNING - Attempt 273: Please wait for sglang server to become ready...
2025-03-20 16:16:30,485 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:16:30,726 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 16:16:31,255 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:16:31,304 - olm-ocr-api - WARNING - Attempt 274: Please wait for sglang server to become ready...
2025-03-20 16:16:31,519 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:16:31,752 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 16:16:32,281 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:16:32,335 - olm-ocr-api - WARNING - Attempt 275: Please wait for sglang server to become ready...
2025-03-20 16:16:32,564 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:16:32,792 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 16:16:33,326 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:16:33,367 - olm-ocr-api - WARNING - Attempt 276: Please wait for sglang server to become ready...
2025-03-20 16:16:33,591 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:16:33,838 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 16:16:34,361 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:16:34,398 - olm-ocr-api - WARNING - Attempt 277: Please wait for sglang server to become ready...
2025-03-20 16:16:34,637 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:16:34,870 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 16:16:35,408 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:16:35,424 - olm-ocr-api - WARNING - Attempt 278: Please wait for sglang server to become ready...
2025-03-20 16:16:35,667 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:16:35,895 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 16:16:36,437 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:16:36,452 - olm-ocr-api - WARNING - Attempt 279: Please wait for sglang server to become ready...
2025-03-20 16:16:36,697 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:16:36,923 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 16:16:37,467 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 16:16:37,483 - olm-ocr-api - WARNING - Attempt 280: Please wait for sglang server to become ready...
2025-03-20 16:16:37,727 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:16:37,952 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 16:16:38,508 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 16:16:38,520 - olm-ocr-api - WARNING - Attempt 281: Please wait for sglang server to become ready...
2025-03-20 16:16:38,752 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:16:38,979 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 16:16:39,532 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 16:16:39,545 - olm-ocr-api - WARNING - Attempt 282: Please wait for sglang server to become ready...
2025-03-20 16:16:39,784 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:16:40,016 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 16:16:40,538 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 16:16:40,558 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 16:16:40,573 - olm-ocr-api - WARNING - Attempt 283: Please wait for sglang server to become ready...
2025-03-20 16:16:40,819 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:16:41,062 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 16:16:41,568 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 16:16:41,602 - olm-ocr-api - WARNING - Attempt 284: Please wait for sglang server to become ready...
2025-03-20 16:16:41,609 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 16:16:41,864 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:16:42,090 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 16:16:42,596 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 16:16:42,627 - olm-ocr-api - WARNING - Attempt 285: Please wait for sglang server to become ready...
2025-03-20 16:16:42,669 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 16:16:42,898 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:16:43,132 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 16:16:43,637 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 16:16:43,653 - olm-ocr-api - WARNING - Attempt 286: Please wait for sglang server to become ready...
2025-03-20 16:16:43,696 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 16:16:43,923 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 16:16:44,158 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 16:16:44,664 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 16:16:44,693 - olm-ocr-api - WARNING - Attempt 287: Please wait for sglang server to become ready...
2025-03-20 16:16:44,723 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 16:16:44,948 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 16:16:45,188 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 16:16:45,711 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 16:16:45,718 - olm-ocr-api - WARNING - Attempt 288: Please wait for sglang server to become ready...
2025-03-20 16:16:45,759 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 16:16:45,979 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 16:16:46,214 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 16:16:46,737 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 16:16:46,745 - olm-ocr-api - WARNING - Attempt 289: Please wait for sglang server to become ready...
2025-03-20 16:16:46,792 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 16:16:47,003 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 16:16:47,250 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 16:16:47,348 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 16:16:47,763 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 16:16:47,797 - olm-ocr-api - WARNING - Attempt 290: Please wait for sglang server to become ready...
2025-03-20 16:16:47,817 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 16:16:48,035 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 16:16:48,277 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 16:16:48,372 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 16:16:48,793 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 16:16:48,843 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 16:16:48,850 - olm-ocr-api - WARNING - Attempt 291: Please wait for sglang server to become ready...
2025-03-20 16:16:49,062 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 16:16:49,306 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 16:16:49,398 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 16:16:49,828 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 16:16:49,868 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 16:16:49,911 - olm-ocr-api - WARNING - Attempt 292: Please wait for sglang server to become ready...
2025-03-20 16:16:50,087 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 16:16:50,332 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 16:16:50,429 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 16:16:50,853 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 16:16:50,899 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 16:16:50,938 - olm-ocr-api - WARNING - Attempt 293: Please wait for sglang server to become ready...
2025-03-20 16:16:51,132 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 16:16:51,366 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 16:16:51,459 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 16:16:51,881 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 16:16:51,943 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 16:16:51,968 - olm-ocr-api - WARNING - Attempt 294: Please wait for sglang server to become ready...
2025-03-20 16:16:52,160 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 16:16:52,401 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 16:16:52,490 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 16:16:52,908 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 16:16:52,976 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 16:16:52,999 - olm-ocr-api - WARNING - Attempt 295: Please wait for sglang server to become ready...
2025-03-20 16:16:53,187 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 16:16:53,430 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 16:16:53,538 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 16:16:53,936 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 16:16:54,005 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 16:16:54,024 - olm-ocr-api - WARNING - Attempt 296: Please wait for sglang server to become ready...
2025-03-20 16:16:54,214 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 16:16:54,461 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 16:16:54,574 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 16:16:54,962 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 16:16:55,034 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 16:16:55,058 - olm-ocr-api - WARNING - Attempt 297: Please wait for sglang server to become ready...
2025-03-20 16:16:55,240 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 16:16:55,496 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 16:16:55,602 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 16:16:55,991 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 16:16:56,062 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 16:16:56,088 - olm-ocr-api - WARNING - Attempt 298: Please wait for sglang server to become ready...
2025-03-20 16:16:56,267 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 16:16:56,527 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 16:16:56,634 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 16:16:57,020 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 16:16:57,087 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 16:16:57,119 - olm-ocr-api - WARNING - Attempt 299: Please wait for sglang server to become ready...
2025-03-20 16:16:57,296 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 16:16:57,555 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 16:16:57,676 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 16:16:58,049 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 16:16:58,114 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 16:16:58,168 - olm-ocr-api - WARNING - Attempt 300: Please wait for sglang server to become ready...
2025-03-20 16:16:58,328 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 16:16:58,584 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 16:16:58,724 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 16:16:59,077 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 16:16:59,145 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 16:16:59,354 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 16:16:59,637 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 16:16:59,753 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 16:17:00,116 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 16:17:00,176 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 16:17:00,380 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 16:17:00,669 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 16:17:00,786 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 16:17:01,145 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 16:17:01,212 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 16:17:01,416 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 16:17:01,694 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 16:17:01,812 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 16:17:02,192 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 16:17:02,238 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 16:17:02,449 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 16:17:02,732 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 16:17:02,847 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 16:17:03,218 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 16:17:03,284 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 16:17:03,478 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 16:17:03,759 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 16:17:03,875 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 16:17:04,267 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 16:17:04,313 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 16:17:04,512 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 16:17:04,790 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 16:17:04,904 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 16:17:05,316 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 16:17:05,339 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 16:17:05,540 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
2025-03-20 16:17:05,815 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 16:17:05,935 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 16:17:06,348 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 16:17:06,369 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 16:17:06,572 - olm-ocr-api - WARNING - Attempt 50: Please wait for sglang server to become ready...
2025-03-20 16:17:06,857 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 16:17:06,965 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 16:17:07,395 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 16:17:07,400 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 16:17:07,605 - olm-ocr-api - WARNING - Attempt 51: Please wait for sglang server to become ready...
2025-03-20 16:17:07,889 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 16:17:07,994 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 16:17:08,427 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 16:17:08,443 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 16:17:08,632 - olm-ocr-api - WARNING - Attempt 52: Please wait for sglang server to become ready...
2025-03-20 16:17:08,921 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 16:17:09,025 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 16:17:09,457 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 16:17:09,473 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 16:17:09,657 - olm-ocr-api - WARNING - Attempt 53: Please wait for sglang server to become ready...
2025-03-20 16:17:09,953 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 16:17:10,052 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 16:17:10,489 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 16:17:10,507 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 16:17:10,689 - olm-ocr-api - WARNING - Attempt 54: Please wait for sglang server to become ready...
2025-03-20 16:17:10,982 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 16:17:11,077 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 16:17:11,522 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 16:17:11,541 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 16:17:11,717 - olm-ocr-api - WARNING - Attempt 55: Please wait for sglang server to become ready...
2025-03-20 16:17:12,025 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 16:17:12,105 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 16:17:12,550 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 16:17:12,574 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 16:17:12,744 - olm-ocr-api - WARNING - Attempt 56: Please wait for sglang server to become ready...
2025-03-20 16:17:13,053 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 16:17:13,153 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 16:17:13,580 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 16:17:13,599 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 16:17:13,776 - olm-ocr-api - WARNING - Attempt 57: Please wait for sglang server to become ready...
2025-03-20 16:17:14,080 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 16:17:14,179 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 16:17:14,615 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 16:17:14,624 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 16:17:14,805 - olm-ocr-api - WARNING - Attempt 58: Please wait for sglang server to become ready...
2025-03-20 16:17:15,106 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 16:17:15,206 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 16:17:15,654 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 16:17:15,664 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 16:17:15,833 - olm-ocr-api - WARNING - Attempt 59: Please wait for sglang server to become ready...
2025-03-20 16:17:16,131 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 16:17:16,233 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 16:17:16,684 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 16:17:16,697 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 16:17:16,867 - olm-ocr-api - WARNING - Attempt 60: Please wait for sglang server to become ready...
2025-03-20 16:17:17,169 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 16:17:17,261 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 16:17:17,710 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 16:17:17,725 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 16:17:17,898 - olm-ocr-api - WARNING - Attempt 61: Please wait for sglang server to become ready...
2025-03-20 16:17:18,201 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 16:17:18,303 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 16:17:18,742 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 16:17:18,755 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 16:17:18,941 - olm-ocr-api - WARNING - Attempt 62: Please wait for sglang server to become ready...
2025-03-20 16:17:19,231 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 16:17:19,332 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 16:17:19,769 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 16:17:19,782 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 16:17:19,986 - olm-ocr-api - WARNING - Attempt 63: Please wait for sglang server to become ready...
2025-03-20 16:17:20,263 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 16:17:20,367 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 16:17:20,802 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 16:17:20,818 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 16:17:21,012 - olm-ocr-api - WARNING - Attempt 64: Please wait for sglang server to become ready...
2025-03-20 16:17:21,309 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 16:17:21,417 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 16:17:21,830 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 16:17:21,855 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 16:17:22,038 - olm-ocr-api - WARNING - Attempt 65: Please wait for sglang server to become ready...
2025-03-20 16:17:22,339 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 16:17:22,447 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 16:17:22,860 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 16:17:22,880 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 16:17:23,074 - olm-ocr-api - WARNING - Attempt 66: Please wait for sglang server to become ready...
2025-03-20 16:17:23,374 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 16:17:23,484 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 16:17:23,892 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 16:17:23,918 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 16:17:24,101 - olm-ocr-api - WARNING - Attempt 67: Please wait for sglang server to become ready...
2025-03-20 16:17:24,410 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 16:17:24,515 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 16:17:24,925 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 16:17:24,946 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 16:17:25,127 - olm-ocr-api - WARNING - Attempt 68: Please wait for sglang server to become ready...
2025-03-20 16:17:25,437 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 16:17:25,544 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 16:17:25,949 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 16:17:25,972 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 16:17:26,158 - olm-ocr-api - WARNING - Attempt 69: Please wait for sglang server to become ready...
2025-03-20 16:17:26,469 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 16:17:26,575 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 16:17:26,977 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 16:17:26,999 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 16:17:27,189 - olm-ocr-api - WARNING - Attempt 70: Please wait for sglang server to become ready...
2025-03-20 16:17:27,500 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 16:17:27,607 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 16:17:28,005 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 16:17:28,042 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 16:17:28,215 - olm-ocr-api - WARNING - Attempt 71: Please wait for sglang server to become ready...
2025-03-20 16:17:28,531 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 16:17:28,631 - olm-ocr-api - WARNING - Attempt 133: Please wait for sglang server to become ready...
2025-03-20 16:17:29,035 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 16:17:29,073 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 16:17:29,246 - olm-ocr-api - WARNING - Attempt 72: Please wait for sglang server to become ready...
2025-03-20 16:17:29,579 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 16:17:29,660 - olm-ocr-api - WARNING - Attempt 134: Please wait for sglang server to become ready...
2025-03-20 16:17:30,084 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 16:17:30,105 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 16:17:30,277 - olm-ocr-api - WARNING - Attempt 73: Please wait for sglang server to become ready...
2025-03-20 16:17:30,614 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 16:17:30,687 - olm-ocr-api - WARNING - Attempt 135: Please wait for sglang server to become ready...
2025-03-20 16:17:31,109 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 16:17:31,131 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 16:17:31,305 - olm-ocr-api - WARNING - Attempt 74: Please wait for sglang server to become ready...
2025-03-20 16:17:31,642 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 16:17:31,714 - olm-ocr-api - WARNING - Attempt 136: Please wait for sglang server to become ready...
2025-03-20 16:17:32,141 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 16:17:32,157 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 16:17:32,343 - olm-ocr-api - WARNING - Attempt 75: Please wait for sglang server to become ready...
2025-03-20 16:17:32,676 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 16:17:32,739 - olm-ocr-api - WARNING - Attempt 137: Please wait for sglang server to become ready...
2025-03-20 16:17:33,167 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 16:17:33,182 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 16:17:33,368 - olm-ocr-api - WARNING - Attempt 76: Please wait for sglang server to become ready...
2025-03-20 16:17:33,701 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 16:17:33,768 - olm-ocr-api - WARNING - Attempt 138: Please wait for sglang server to become ready...
2025-03-20 16:17:34,192 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 16:17:34,216 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 16:17:34,405 - olm-ocr-api - WARNING - Attempt 77: Please wait for sglang server to become ready...
2025-03-20 16:17:34,750 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 16:17:34,796 - olm-ocr-api - WARNING - Attempt 139: Please wait for sglang server to become ready...
2025-03-20 16:17:35,221 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 16:17:35,243 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 16:17:35,431 - olm-ocr-api - WARNING - Attempt 78: Please wait for sglang server to become ready...
2025-03-20 16:17:35,775 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 16:17:35,822 - olm-ocr-api - WARNING - Attempt 140: Please wait for sglang server to become ready...
2025-03-20 16:17:36,254 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 16:17:36,270 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 16:17:36,461 - olm-ocr-api - WARNING - Attempt 79: Please wait for sglang server to become ready...
2025-03-20 16:17:36,829 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 16:17:36,849 - olm-ocr-api - WARNING - Attempt 141: Please wait for sglang server to become ready...
2025-03-20 16:17:37,282 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 16:17:37,298 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 16:17:37,499 - olm-ocr-api - WARNING - Attempt 80: Please wait for sglang server to become ready...
2025-03-20 16:17:37,859 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 16:17:37,874 - olm-ocr-api - WARNING - Attempt 142: Please wait for sglang server to become ready...
2025-03-20 16:17:38,312 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 16:17:38,335 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 16:17:38,540 - olm-ocr-api - WARNING - Attempt 81: Please wait for sglang server to become ready...
2025-03-20 16:17:38,892 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 16:17:38,906 - olm-ocr-api - WARNING - Attempt 143: Please wait for sglang server to become ready...
2025-03-20 16:17:39,338 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 16:17:39,362 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 16:17:39,565 - olm-ocr-api - WARNING - Attempt 82: Please wait for sglang server to become ready...
2025-03-20 16:17:39,943 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 16:17:39,956 - olm-ocr-api - WARNING - Attempt 144: Please wait for sglang server to become ready...
2025-03-20 16:17:40,382 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 16:17:40,392 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 16:17:40,592 - olm-ocr-api - WARNING - Attempt 83: Please wait for sglang server to become ready...
2025-03-20 16:17:40,980 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 16:17:41,011 - olm-ocr-api - WARNING - Attempt 145: Please wait for sglang server to become ready...
2025-03-20 16:17:41,416 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 16:17:41,447 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 16:17:41,625 - olm-ocr-api - WARNING - Attempt 84: Please wait for sglang server to become ready...
2025-03-20 16:17:42,007 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 16:17:42,043 - olm-ocr-api - WARNING - Attempt 146: Please wait for sglang server to become ready...
2025-03-20 16:17:42,443 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 16:17:42,474 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 16:17:42,650 - olm-ocr-api - WARNING - Attempt 85: Please wait for sglang server to become ready...
2025-03-20 16:17:43,037 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 16:17:43,073 - olm-ocr-api - WARNING - Attempt 147: Please wait for sglang server to become ready...
2025-03-20 16:17:43,470 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 16:17:43,500 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 16:17:43,691 - olm-ocr-api - WARNING - Attempt 86: Please wait for sglang server to become ready...
2025-03-20 16:17:44,063 - olm-ocr-api - WARNING - Attempt 133: Please wait for sglang server to become ready...
2025-03-20 16:17:44,104 - olm-ocr-api - WARNING - Attempt 148: Please wait for sglang server to become ready...
2025-03-20 16:17:44,498 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 16:17:44,534 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 16:17:44,721 - olm-ocr-api - WARNING - Attempt 87: Please wait for sglang server to become ready...
2025-03-20 16:17:45,089 - olm-ocr-api - WARNING - Attempt 134: Please wait for sglang server to become ready...
2025-03-20 16:17:45,137 - olm-ocr-api - WARNING - Attempt 149: Please wait for sglang server to become ready...
2025-03-20 16:17:45,523 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 16:17:45,567 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 16:17:45,752 - olm-ocr-api - WARNING - Attempt 88: Please wait for sglang server to become ready...
2025-03-20 16:17:46,114 - olm-ocr-api - WARNING - Attempt 135: Please wait for sglang server to become ready...
2025-03-20 16:17:46,168 - olm-ocr-api - WARNING - Attempt 150: Please wait for sglang server to become ready...
2025-03-20 16:17:46,553 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 16:17:46,595 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 16:17:46,783 - olm-ocr-api - WARNING - Attempt 89: Please wait for sglang server to become ready...
2025-03-20 16:17:47,145 - olm-ocr-api - WARNING - Attempt 136: Please wait for sglang server to become ready...
2025-03-20 16:17:47,194 - olm-ocr-api - WARNING - Attempt 151: Please wait for sglang server to become ready...
2025-03-20 16:17:47,584 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 16:17:47,621 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 16:17:47,814 - olm-ocr-api - WARNING - Attempt 90: Please wait for sglang server to become ready...
2025-03-20 16:17:48,180 - olm-ocr-api - WARNING - Attempt 137: Please wait for sglang server to become ready...
2025-03-20 16:17:48,225 - olm-ocr-api - WARNING - Attempt 152: Please wait for sglang server to become ready...
2025-03-20 16:17:48,609 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 16:17:48,657 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 16:17:48,839 - olm-ocr-api - WARNING - Attempt 91: Please wait for sglang server to become ready...
2025-03-20 16:17:49,207 - olm-ocr-api - WARNING - Attempt 138: Please wait for sglang server to become ready...
2025-03-20 16:17:49,251 - olm-ocr-api - WARNING - Attempt 153: Please wait for sglang server to become ready...
2025-03-20 16:17:49,638 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 16:17:49,684 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 16:17:49,867 - olm-ocr-api - WARNING - Attempt 92: Please wait for sglang server to become ready...
2025-03-20 16:17:50,242 - olm-ocr-api - WARNING - Attempt 139: Please wait for sglang server to become ready...
2025-03-20 16:17:50,276 - olm-ocr-api - WARNING - Attempt 154: Please wait for sglang server to become ready...
2025-03-20 16:17:50,670 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 16:17:50,719 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 16:17:50,915 - olm-ocr-api - WARNING - Attempt 93: Please wait for sglang server to become ready...
2025-03-20 16:17:51,274 - olm-ocr-api - WARNING - Attempt 140: Please wait for sglang server to become ready...
2025-03-20 16:17:51,304 - olm-ocr-api - WARNING - Attempt 155: Please wait for sglang server to become ready...
2025-03-20 16:17:51,703 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 16:17:51,747 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 16:17:51,940 - olm-ocr-api - WARNING - Attempt 94: Please wait for sglang server to become ready...
2025-03-20 16:17:52,314 - olm-ocr-api - WARNING - Attempt 141: Please wait for sglang server to become ready...
2025-03-20 16:17:52,352 - olm-ocr-api - WARNING - Attempt 156: Please wait for sglang server to become ready...
2025-03-20 16:17:52,730 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 16:17:52,775 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 16:17:52,968 - olm-ocr-api - WARNING - Attempt 95: Please wait for sglang server to become ready...
2025-03-20 16:17:53,346 - olm-ocr-api - WARNING - Attempt 142: Please wait for sglang server to become ready...
2025-03-20 16:17:53,400 - olm-ocr-api - WARNING - Attempt 157: Please wait for sglang server to become ready...
2025-03-20 16:17:53,758 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 16:17:53,804 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 16:17:54,002 - olm-ocr-api - WARNING - Attempt 96: Please wait for sglang server to become ready...
2025-03-20 16:17:54,394 - olm-ocr-api - WARNING - Attempt 143: Please wait for sglang server to become ready...
2025-03-20 16:17:54,425 - olm-ocr-api - WARNING - Attempt 158: Please wait for sglang server to become ready...
2025-03-20 16:17:54,786 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 16:17:54,833 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 16:17:55,035 - olm-ocr-api - WARNING - Attempt 97: Please wait for sglang server to become ready...
2025-03-20 16:17:55,426 - olm-ocr-api - WARNING - Attempt 144: Please wait for sglang server to become ready...
2025-03-20 16:17:55,477 - olm-ocr-api - WARNING - Attempt 159: Please wait for sglang server to become ready...
2025-03-20 16:17:55,819 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 16:17:55,863 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 16:17:56,069 - olm-ocr-api - WARNING - Attempt 98: Please wait for sglang server to become ready...
2025-03-20 16:17:56,459 - olm-ocr-api - WARNING - Attempt 145: Please wait for sglang server to become ready...
2025-03-20 16:17:56,525 - olm-ocr-api - WARNING - Attempt 160: Please wait for sglang server to become ready...
2025-03-20 16:17:56,852 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 16:17:56,892 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 16:17:57,101 - olm-ocr-api - WARNING - Attempt 99: Please wait for sglang server to become ready...
2025-03-20 16:17:57,485 - olm-ocr-api - WARNING - Attempt 146: Please wait for sglang server to become ready...
2025-03-20 16:17:57,556 - olm-ocr-api - WARNING - Attempt 161: Please wait for sglang server to become ready...
2025-03-20 16:17:57,888 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 16:17:57,917 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 16:17:58,130 - olm-ocr-api - WARNING - Attempt 100: Please wait for sglang server to become ready...
2025-03-20 16:17:58,515 - olm-ocr-api - WARNING - Attempt 147: Please wait for sglang server to become ready...
2025-03-20 16:17:58,592 - olm-ocr-api - WARNING - Attempt 162: Please wait for sglang server to become ready...
2025-03-20 16:17:58,915 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 16:17:58,952 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 16:17:59,166 - olm-ocr-api - WARNING - Attempt 101: Please wait for sglang server to become ready...
2025-03-20 16:17:59,545 - olm-ocr-api - WARNING - Attempt 148: Please wait for sglang server to become ready...
2025-03-20 16:17:59,619 - olm-ocr-api - WARNING - Attempt 163: Please wait for sglang server to become ready...
2025-03-20 16:17:59,942 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 16:17:59,982 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 16:18:00,192 - olm-ocr-api - WARNING - Attempt 102: Please wait for sglang server to become ready...
2025-03-20 16:18:00,579 - olm-ocr-api - WARNING - Attempt 149: Please wait for sglang server to become ready...
2025-03-20 16:18:00,645 - olm-ocr-api - WARNING - Attempt 164: Please wait for sglang server to become ready...
2025-03-20 16:18:00,971 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 16:18:01,017 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 16:18:01,245 - olm-ocr-api - WARNING - Attempt 103: Please wait for sglang server to become ready...
2025-03-20 16:18:01,612 - olm-ocr-api - WARNING - Attempt 150: Please wait for sglang server to become ready...
2025-03-20 16:18:01,693 - olm-ocr-api - WARNING - Attempt 165: Please wait for sglang server to become ready...
2025-03-20 16:18:02,000 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 16:18:02,045 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 16:18:02,275 - olm-ocr-api - WARNING - Attempt 104: Please wait for sglang server to become ready...
2025-03-20 16:18:02,642 - olm-ocr-api - WARNING - Attempt 151: Please wait for sglang server to become ready...
2025-03-20 16:18:02,729 - olm-ocr-api - WARNING - Attempt 166: Please wait for sglang server to become ready...
2025-03-20 16:18:03,037 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 16:18:03,071 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 16:18:03,302 - olm-ocr-api - WARNING - Attempt 105: Please wait for sglang server to become ready...
2025-03-20 16:18:03,685 - olm-ocr-api - WARNING - Attempt 152: Please wait for sglang server to become ready...
2025-03-20 16:18:03,776 - olm-ocr-api - WARNING - Attempt 167: Please wait for sglang server to become ready...
2025-03-20 16:18:04,064 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 16:18:04,100 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 16:18:04,350 - olm-ocr-api - WARNING - Attempt 106: Please wait for sglang server to become ready...
2025-03-20 16:18:04,714 - olm-ocr-api - WARNING - Attempt 153: Please wait for sglang server to become ready...
2025-03-20 16:18:04,802 - olm-ocr-api - WARNING - Attempt 168: Please wait for sglang server to become ready...
2025-03-20 16:18:05,093 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 16:18:05,127 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 16:18:05,379 - olm-ocr-api - WARNING - Attempt 107: Please wait for sglang server to become ready...
2025-03-20 16:18:05,749 - olm-ocr-api - WARNING - Attempt 154: Please wait for sglang server to become ready...
2025-03-20 16:18:05,828 - olm-ocr-api - WARNING - Attempt 169: Please wait for sglang server to become ready...
2025-03-20 16:18:06,127 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 16:18:06,152 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 16:18:06,409 - olm-ocr-api - WARNING - Attempt 108: Please wait for sglang server to become ready...
2025-03-20 16:18:06,778 - olm-ocr-api - WARNING - Attempt 155: Please wait for sglang server to become ready...
2025-03-20 16:18:06,857 - olm-ocr-api - WARNING - Attempt 170: Please wait for sglang server to become ready...
2025-03-20 16:18:07,155 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 16:18:07,190 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 16:18:07,441 - olm-ocr-api - WARNING - Attempt 109: Please wait for sglang server to become ready...
2025-03-20 16:18:07,839 - olm-ocr-api - WARNING - Attempt 156: Please wait for sglang server to become ready...
2025-03-20 16:18:07,888 - olm-ocr-api - WARNING - Attempt 171: Please wait for sglang server to become ready...
2025-03-20 16:18:08,182 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 16:18:08,240 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 16:18:08,482 - olm-ocr-api - WARNING - Attempt 110: Please wait for sglang server to become ready...
2025-03-20 16:18:08,871 - olm-ocr-api - WARNING - Attempt 157: Please wait for sglang server to become ready...
2025-03-20 16:18:08,939 - olm-ocr-api - WARNING - Attempt 172: Please wait for sglang server to become ready...
2025-03-20 16:18:09,208 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 16:18:09,267 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 16:18:09,511 - olm-ocr-api - WARNING - Attempt 111: Please wait for sglang server to become ready...
2025-03-20 16:18:09,900 - olm-ocr-api - WARNING - Attempt 158: Please wait for sglang server to become ready...
2025-03-20 16:18:09,969 - olm-ocr-api - WARNING - Attempt 173: Please wait for sglang server to become ready...
2025-03-20 16:18:10,256 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 16:18:10,294 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 16:18:10,540 - olm-ocr-api - WARNING - Attempt 112: Please wait for sglang server to become ready...
2025-03-20 16:18:10,930 - olm-ocr-api - WARNING - Attempt 159: Please wait for sglang server to become ready...
2025-03-20 16:18:10,997 - olm-ocr-api - WARNING - Attempt 174: Please wait for sglang server to become ready...
2025-03-20 16:18:11,282 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 16:18:11,325 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 16:18:11,572 - olm-ocr-api - WARNING - Attempt 113: Please wait for sglang server to become ready...
2025-03-20 16:18:11,965 - olm-ocr-api - WARNING - Attempt 160: Please wait for sglang server to become ready...
2025-03-20 16:18:12,030 - olm-ocr-api - WARNING - Attempt 175: Please wait for sglang server to become ready...
2025-03-20 16:18:12,335 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 16:18:12,362 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 16:18:12,599 - olm-ocr-api - WARNING - Attempt 114: Please wait for sglang server to become ready...
2025-03-20 16:18:12,995 - olm-ocr-api - WARNING - Attempt 161: Please wait for sglang server to become ready...
2025-03-20 16:18:13,057 - olm-ocr-api - WARNING - Attempt 176: Please wait for sglang server to become ready...
2025-03-20 16:18:13,382 - olm-ocr-api - WARNING - Attempt 133: Please wait for sglang server to become ready...
2025-03-20 16:18:13,411 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 16:18:13,631 - olm-ocr-api - WARNING - Attempt 115: Please wait for sglang server to become ready...
2025-03-20 16:18:14,023 - olm-ocr-api - WARNING - Attempt 162: Please wait for sglang server to become ready...
2025-03-20 16:18:14,084 - olm-ocr-api - WARNING - Attempt 177: Please wait for sglang server to become ready...
2025-03-20 16:18:14,420 - olm-ocr-api - WARNING - Attempt 134: Please wait for sglang server to become ready...
2025-03-20 16:18:14,449 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 16:18:14,684 - olm-ocr-api - WARNING - Attempt 116: Please wait for sglang server to become ready...
2025-03-20 16:18:15,051 - olm-ocr-api - WARNING - Attempt 163: Please wait for sglang server to become ready...
2025-03-20 16:18:15,121 - olm-ocr-api - WARNING - Attempt 178: Please wait for sglang server to become ready...
2025-03-20 16:18:15,450 - olm-ocr-api - WARNING - Attempt 135: Please wait for sglang server to become ready...
2025-03-20 16:18:15,479 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 16:18:15,719 - olm-ocr-api - WARNING - Attempt 117: Please wait for sglang server to become ready...
2025-03-20 16:18:16,079 - olm-ocr-api - WARNING - Attempt 164: Please wait for sglang server to become ready...
2025-03-20 16:18:16,154 - olm-ocr-api - WARNING - Attempt 179: Please wait for sglang server to become ready...
2025-03-20 16:18:16,480 - olm-ocr-api - WARNING - Attempt 136: Please wait for sglang server to become ready...
2025-03-20 16:18:16,505 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 16:18:16,749 - olm-ocr-api - WARNING - Attempt 118: Please wait for sglang server to become ready...
2025-03-20 16:18:17,105 - olm-ocr-api - WARNING - Attempt 165: Please wait for sglang server to become ready...
2025-03-20 16:18:17,187 - olm-ocr-api - WARNING - Attempt 180: Please wait for sglang server to become ready...
2025-03-20 16:18:17,506 - olm-ocr-api - WARNING - Attempt 137: Please wait for sglang server to become ready...
2025-03-20 16:18:17,533 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 16:18:17,780 - olm-ocr-api - WARNING - Attempt 119: Please wait for sglang server to become ready...
2025-03-20 16:18:18,137 - olm-ocr-api - WARNING - Attempt 166: Please wait for sglang server to become ready...
2025-03-20 16:18:18,212 - olm-ocr-api - WARNING - Attempt 181: Please wait for sglang server to become ready...
2025-03-20 16:18:18,539 - olm-ocr-api - WARNING - Attempt 138: Please wait for sglang server to become ready...
2025-03-20 16:18:18,566 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 16:18:18,811 - olm-ocr-api - WARNING - Attempt 120: Please wait for sglang server to become ready...
2025-03-20 16:18:19,193 - olm-ocr-api - WARNING - Attempt 167: Please wait for sglang server to become ready...
2025-03-20 16:18:19,237 - olm-ocr-api - WARNING - Attempt 182: Please wait for sglang server to become ready...
2025-03-20 16:18:19,572 - olm-ocr-api - WARNING - Attempt 139: Please wait for sglang server to become ready...
2025-03-20 16:18:19,594 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 16:18:19,839 - olm-ocr-api - WARNING - Attempt 121: Please wait for sglang server to become ready...
2025-03-20 16:18:20,223 - olm-ocr-api - WARNING - Attempt 168: Please wait for sglang server to become ready...
2025-03-20 16:18:20,267 - olm-ocr-api - WARNING - Attempt 183: Please wait for sglang server to become ready...
2025-03-20 16:18:20,607 - olm-ocr-api - WARNING - Attempt 140: Please wait for sglang server to become ready...
2025-03-20 16:18:20,626 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 16:18:20,885 - olm-ocr-api - WARNING - Attempt 122: Please wait for sglang server to become ready...
2025-03-20 16:18:21,249 - olm-ocr-api - WARNING - Attempt 169: Please wait for sglang server to become ready...
2025-03-20 16:18:21,305 - olm-ocr-api - WARNING - Attempt 184: Please wait for sglang server to become ready...
2025-03-20 16:18:21,638 - olm-ocr-api - WARNING - Attempt 141: Please wait for sglang server to become ready...
2025-03-20 16:18:21,659 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 16:18:21,914 - olm-ocr-api - WARNING - Attempt 123: Please wait for sglang server to become ready...
2025-03-20 16:18:22,297 - olm-ocr-api - WARNING - Attempt 170: Please wait for sglang server to become ready...
2025-03-20 16:18:22,333 - olm-ocr-api - WARNING - Attempt 185: Please wait for sglang server to become ready...
2025-03-20 16:18:22,666 - olm-ocr-api - WARNING - Attempt 142: Please wait for sglang server to become ready...
2025-03-20 16:18:22,709 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 16:18:22,942 - olm-ocr-api - WARNING - Attempt 124: Please wait for sglang server to become ready...
2025-03-20 16:18:23,322 - olm-ocr-api - WARNING - Attempt 171: Please wait for sglang server to become ready...
2025-03-20 16:18:23,362 - olm-ocr-api - WARNING - Attempt 186: Please wait for sglang server to become ready...
2025-03-20 16:18:23,692 - olm-ocr-api - WARNING - Attempt 143: Please wait for sglang server to become ready...
2025-03-20 16:18:23,756 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 16:18:23,974 - olm-ocr-api - WARNING - Attempt 125: Please wait for sglang server to become ready...
2025-03-20 16:18:24,374 - olm-ocr-api - WARNING - Attempt 172: Please wait for sglang server to become ready...
2025-03-20 16:18:24,390 - olm-ocr-api - WARNING - Attempt 187: Please wait for sglang server to become ready...
2025-03-20 16:18:24,719 - olm-ocr-api - WARNING - Attempt 144: Please wait for sglang server to become ready...
2025-03-20 16:18:24,786 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 16:18:25,003 - olm-ocr-api - WARNING - Attempt 126: Please wait for sglang server to become ready...
2025-03-20 16:18:25,404 - olm-ocr-api - WARNING - Attempt 173: Please wait for sglang server to become ready...
2025-03-20 16:18:25,417 - olm-ocr-api - WARNING - Attempt 188: Please wait for sglang server to become ready...
2025-03-20 16:18:25,745 - olm-ocr-api - WARNING - Attempt 145: Please wait for sglang server to become ready...
2025-03-20 16:18:25,816 - olm-ocr-api - WARNING - Attempt 133: Please wait for sglang server to become ready...
2025-03-20 16:18:26,045 - olm-ocr-api - WARNING - Attempt 127: Please wait for sglang server to become ready...
2025-03-20 16:18:26,430 - olm-ocr-api - WARNING - Attempt 174: Please wait for sglang server to become ready...
2025-03-20 16:18:26,446 - olm-ocr-api - WARNING - Attempt 189: Please wait for sglang server to become ready...
2025-03-20 16:18:26,772 - olm-ocr-api - WARNING - Attempt 146: Please wait for sglang server to become ready...
2025-03-20 16:18:26,855 - olm-ocr-api - WARNING - Attempt 134: Please wait for sglang server to become ready...
2025-03-20 16:18:27,082 - olm-ocr-api - WARNING - Attempt 128: Please wait for sglang server to become ready...
2025-03-20 16:18:27,461 - olm-ocr-api - WARNING - Attempt 175: Please wait for sglang server to become ready...
2025-03-20 16:18:27,472 - olm-ocr-api - WARNING - Attempt 190: Please wait for sglang server to become ready...
2025-03-20 16:18:27,800 - olm-ocr-api - WARNING - Attempt 147: Please wait for sglang server to become ready...
2025-03-20 16:18:27,893 - olm-ocr-api - WARNING - Attempt 135: Please wait for sglang server to become ready...
2025-03-20 16:18:28,117 - olm-ocr-api - WARNING - Attempt 129: Please wait for sglang server to become ready...
2025-03-20 16:18:28,488 - olm-ocr-api - WARNING - Attempt 176: Please wait for sglang server to become ready...
2025-03-20 16:18:28,498 - olm-ocr-api - WARNING - Attempt 191: Please wait for sglang server to become ready...
2025-03-20 16:18:28,825 - olm-ocr-api - WARNING - Attempt 148: Please wait for sglang server to become ready...
2025-03-20 16:18:28,925 - olm-ocr-api - WARNING - Attempt 136: Please wait for sglang server to become ready...
2025-03-20 16:18:29,151 - olm-ocr-api - WARNING - Attempt 130: Please wait for sglang server to become ready...
2025-03-20 16:18:29,524 - olm-ocr-api - WARNING - Attempt 177: Please wait for sglang server to become ready...
2025-03-20 16:18:29,543 - olm-ocr-api - WARNING - Attempt 192: Please wait for sglang server to become ready...
2025-03-20 16:18:29,853 - olm-ocr-api - WARNING - Attempt 149: Please wait for sglang server to become ready...
2025-03-20 16:18:29,951 - olm-ocr-api - WARNING - Attempt 137: Please wait for sglang server to become ready...
2025-03-20 16:18:30,177 - olm-ocr-api - WARNING - Attempt 131: Please wait for sglang server to become ready...
2025-03-20 16:18:30,555 - olm-ocr-api - WARNING - Attempt 178: Please wait for sglang server to become ready...
2025-03-20 16:18:30,574 - olm-ocr-api - WARNING - Attempt 193: Please wait for sglang server to become ready...
2025-03-20 16:18:30,884 - olm-ocr-api - WARNING - Attempt 150: Please wait for sglang server to become ready...
2025-03-20 16:18:30,977 - olm-ocr-api - WARNING - Attempt 138: Please wait for sglang server to become ready...
2025-03-20 16:18:31,202 - olm-ocr-api - WARNING - Attempt 132: Please wait for sglang server to become ready...
2025-03-20 16:18:31,583 - olm-ocr-api - WARNING - Attempt 179: Please wait for sglang server to become ready...
2025-03-20 16:18:31,624 - olm-ocr-api - WARNING - Attempt 194: Please wait for sglang server to become ready...
2025-03-20 16:24:17,207 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:24:17,209 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:24:19,530 - olm-ocr-api - INFO - INFO 03-20 16:24:19 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:24:22,365 - olm-ocr-api - INFO - [2025-03-20 16:24:22] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=1004652232, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:24:25,572 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:24:25,572 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:24:25,688 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:24:25,688 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:24:26,913 - olm-ocr-api - INFO - [2025-03-20 16:24:26] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:24:28,115 - olm-ocr-api - INFO - INFO 03-20 16:24:28 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:24:28,236 - olm-ocr-api - INFO - INFO 03-20 16:24:28 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:24:38,404 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:24:38,442 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:24:38,442 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:24:38,442 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Init torch distributed begin.
2025-03-20 16:24:38,736 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 16:24:38,737 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] Load weight begin. avail mem=3.86 GB
2025-03-20 16:24:38,829 - olm-ocr-api - INFO - [2025-03-20 16:24:38 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 16:24:39,016 - olm-ocr-api - INFO - [2025-03-20 16:24:39 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:24:39,016 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 176, in initialize
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.load_model()
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 361, in load_model
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.model = get_model(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -                  ^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     return loader.load_model(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 358, in load_model
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     model = _initialize_model(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -             ^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 139, in _initialize_model
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     return model_class(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -            ^^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/models/qwen2_vl.py", line 455, in __init__
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.model = Qwen2Model(
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -                  ^^^^^^^^^^^
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 252, in __init__
2025-03-20 16:24:39,017 - olm-ocr-api - INFO -     self.layers = make_layers(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -                   ^^^^^^^^^^^^
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/utils.py", line 336, in make_layers
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     [
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/utils.py", line 337, in <listcomp>
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     maybe_offload_to_cpu(layer_fn(idx=idx, prefix=add_prefix(idx, prefix)))
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 254, in <lambda>
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     lambda idx, prefix: Qwen2DecoderLayer(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 198, in __init__
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     self.mlp = Qwen2MLP(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -                ^^^^^^^^^
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 63, in __init__
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     self.gate_up_proj = MergedColumnParallelLinear(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/linear.py", line 507, in __init__
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     super().__init__(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/linear.py", line 360, in __init__
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     self.quant_method.create_weights(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/linear.py", line 154, in create_weights
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     torch.empty(
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/_device.py", line 106, in __torch_function__
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -     return func(*args, **kwargs)
2025-03-20 16:24:39,018 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:24:39,019 - olm-ocr-api - INFO - torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 32.44 MiB is free. Process 2543553 has 37.89 GiB memory in use. Process 2549341 has 2.32 GiB memory in use. Including non-PyTorch memory, this process has 4.08 GiB memory in use. Of the allocated memory 3.65 GiB is allocated by PyTorch, and 130.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-03-20 16:24:39,019 - olm-ocr-api - INFO - 
2025-03-20 16:24:39,019 - olm-ocr-api - INFO - [2025-03-20 16:24:39] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:24:39,204 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:24:40,229 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:24:41,268 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:24:42,293 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:24:43,322 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:24:44,355 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:24:45,387 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:24:46,416 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:24:47,446 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:24:48,483 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:25:13,014 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:25:14,061 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:25:15,110 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:25:16,158 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:25:17,188 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:25:18,216 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:25:19,246 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:25:20,279 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:26:37,183 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:26:37,184 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:26:39,618 - olm-ocr-api - INFO - INFO 03-20 16:26:39 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:26:42,697 - olm-ocr-api - INFO - [2025-03-20 16:26:42] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=558393617, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:26:45,165 - olm-ocr-api - INFO - [2025-03-20 16:26:45] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:26:45,875 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:26:45,875 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:26:45,888 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:26:45,888 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:26:48,726 - olm-ocr-api - INFO - INFO 03-20 16:26:48 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:26:48,745 - olm-ocr-api - INFO - INFO 03-20 16:26:48 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:26:52,388 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:26:52,439 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:26:52,439 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:26:52,439 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Init torch distributed begin.
2025-03-20 16:26:52,640 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 16:26:52,640 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] Load weight begin. avail mem=30.84 GB
2025-03-20 16:26:52,730 - olm-ocr-api - INFO - [2025-03-20 16:26:52 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 16:26:53,028 - olm-ocr-api - INFO - [2025-03-20 16:26:53 TP0] Using model weights format ['*.safetensors']
2025-03-20 16:26:53,110 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 16:26:59,267 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:06<00:18,  6.16s/it]
2025-03-20 16:27:05,530 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:12<00:12,  6.22s/it]
2025-03-20 16:27:11,762 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:18<00:06,  6.23s/it]
2025-03-20 16:27:14,047 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:20<00:00,  4.67s/it]
2025-03-20 16:27:14,047 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:20<00:00,  5.23s/it]
2025-03-20 16:27:14,047 - olm-ocr-api - INFO - 
2025-03-20 16:27:14,908 - olm-ocr-api - INFO - [2025-03-20 16:27:14 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=15.12 GB, mem usage=15.72 GB.
2025-03-20 16:27:15,432 - olm-ocr-api - INFO - [2025-03-20 16:27:15 TP0] KV Cache is allocated. #tokens: 144533, K size: 3.86 GB, V size: 3.86 GB
2025-03-20 16:27:15,433 - olm-ocr-api - INFO - [2025-03-20 16:27:15 TP0] Memory pool end. avail mem=7.06 GB
2025-03-20 16:27:15,661 - olm-ocr-api - INFO - 2025-03-20 16:27:15,660 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 16:27:15,686 - olm-ocr-api - INFO - [2025-03-20 16:27:15 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.56 GB
2025-03-20 16:27:16,637 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 16:27:16,636 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 16:27:16,660 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]
2025-03-20 16:27:16,671 - olm-ocr-api - INFO - [2025-03-20 16:27:16 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:27:16,671 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2104, in _run_ninja_build
2025-03-20 16:27:16,671 - olm-ocr-api - INFO -     subprocess.run(
2025-03-20 16:27:16,671 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/subprocess.py", line 571, in run
2025-03-20 16:27:16,671 - olm-ocr-api - INFO -     raise CalledProcessError(retcode, process.args,
2025-03-20 16:27:16,672 - olm-ocr-api - INFO - subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
2025-03-20 16:27:16,672 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,672 - olm-ocr-api - INFO - The above exception was the direct cause of the following exception:
2025-03-20 16:27:16,672 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,672 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     self.capture()
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,672 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1833, in _write_ninja_file_and_build_library
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     _run_ninja_build(
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2120, in _run_ninja_build
2025-03-20 16:27:16,673 - olm-ocr-api - INFO -     raise RuntimeError(message) from e
2025-03-20 16:27:16,674 - olm-ocr-api - INFO - RuntimeError: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,674 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,674 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,679 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,680 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:27:16,681 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:27:16,686 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,716 - olm-ocr-api - INFO - During handling of the above exception, another exception occurred:
2025-03-20 16:27:16,717 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,717 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 254, in __init__
2025-03-20 16:27:16,717 - olm-ocr-api - INFO -     raise Exception(
2025-03-20 16:27:16,717 - olm-ocr-api - INFO - Exception: Capture cuda graph failed: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,717 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,717 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,718 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,815 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,815 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:27:16,815 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/lib/bin/nvcc: No such file or directory
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - Possible solutions:
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 1. disable cuda graph by --disable-cuda-graph
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 2. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 3. disable torch compile by not using --enable-torch-compile
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 4. set --cuda-graph-max-bs to a smaller value (e.g., 32)
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,816 - olm-ocr-api - INFO - 
2025-03-20 16:27:16,817 - olm-ocr-api - INFO - [2025-03-20 16:27:16] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:27:16,917 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:27:17,947 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:27:19,000 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:27:20,046 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:27:21,072 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:27:22,103 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:27:23,131 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:27:24,155 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:27:25,185 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:27:26,212 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:27:27,271 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:27:28,331 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:27:29,356 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:27:30,386 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:27:31,411 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:27:32,447 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:27:33,474 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:27:34,503 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:27:35,532 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:27:36,558 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:27:37,590 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:27:38,616 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:27:57,569 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:27:58,595 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:27:59,628 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:28:00,664 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:28:01,694 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:34:13,281 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:34:13,282 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:34:15,828 - olm-ocr-api - INFO - INFO 03-20 16:34:15 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:34:18,624 - olm-ocr-api - INFO - [2025-03-20 16:34:18] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=937219088, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:34:20,099 - olm-ocr-api - INFO - [2025-03-20 16:34:20] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:34:21,903 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:34:21,903 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:34:21,922 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:34:21,922 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:34:24,667 - olm-ocr-api - INFO - INFO 03-20 16:34:24 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:34:24,671 - olm-ocr-api - INFO - INFO 03-20 16:34:24 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:34:28,325 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:34:28,369 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:34:28,369 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:34:28,369 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Init torch distributed begin.
2025-03-20 16:34:28,531 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 16:34:28,531 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Load weight begin. avail mem=30.84 GB
2025-03-20 16:34:28,613 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 16:34:28,865 - olm-ocr-api - INFO - [2025-03-20 16:34:28 TP0] Using model weights format ['*.safetensors']
2025-03-20 16:34:29,056 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 16:34:35,196 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:06<00:18,  6.14s/it]
2025-03-20 16:34:40,966 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:11<00:11,  5.92s/it]
2025-03-20 16:34:42,749 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:13<00:04,  4.03s/it]
2025-03-20 16:34:43,392 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:14<00:00,  2.69s/it]
2025-03-20 16:34:43,392 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:14<00:00,  3.58s/it]
2025-03-20 16:34:43,392 - olm-ocr-api - INFO - 
2025-03-20 16:34:43,586 - olm-ocr-api - INFO - [2025-03-20 16:34:43 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=15.12 GB, mem usage=15.72 GB.
2025-03-20 16:34:44,131 - olm-ocr-api - INFO - [2025-03-20 16:34:44 TP0] KV Cache is allocated. #tokens: 144533, K size: 3.86 GB, V size: 3.86 GB
2025-03-20 16:34:44,131 - olm-ocr-api - INFO - [2025-03-20 16:34:44 TP0] Memory pool end. avail mem=7.06 GB
2025-03-20 16:34:44,276 - olm-ocr-api - INFO - 2025-03-20 16:34:44,276 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 16:34:44,291 - olm-ocr-api - INFO - [2025-03-20 16:34:44 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.56 GB
2025-03-20 16:34:44,959 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 16:34:44,959 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 16:34:44,976 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - [2025-03-20 16:34:44 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2104, in _run_ninja_build
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -     subprocess.run(
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/subprocess.py", line 571, in run
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -     raise CalledProcessError(retcode, process.args,
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - 
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - The above exception was the direct cause of the following exception:
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - 
2025-03-20 16:34:44,979 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -     self.capture()
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 16:34:44,979 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 16:34:44,980 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1833, in _write_ninja_file_and_build_library
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -     _run_ninja_build(
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2120, in _run_ninja_build
2025-03-20 16:34:44,981 - olm-ocr-api - INFO -     raise RuntimeError(message) from e
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - RuntimeError: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,981 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:44,982 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:44,983 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:34:44,983 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:34:44,983 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:34:45,024 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - During handling of the above exception, another exception occurred:
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,025 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:34:45,025 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 254, in __init__
2025-03-20 16:34:45,026 - olm-ocr-api - INFO -     raise Exception(
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - Exception: Capture cuda graph failed: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,026 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,027 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,089 - olm-ocr-api - INFO - Possible solutions:
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 1. disable cuda graph by --disable-cuda-graph
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 2. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 3. disable torch compile by not using --enable-torch-compile
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 4. set --cuda-graph-max-bs to a smaller value (e.g., 32)
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - 
2025-03-20 16:34:45,090 - olm-ocr-api - INFO - [2025-03-20 16:34:44] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:34:45,173 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:34:46,205 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:34:47,234 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:34:48,265 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:34:49,294 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:34:50,322 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:34:51,359 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:34:52,385 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:34:53,420 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:40:28,789 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:40:29,816 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:40:30,843 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:40:31,872 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:40:32,901 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:42:11,143 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:42:11,143 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:42:14,112 - olm-ocr-api - INFO - INFO 03-20 16:42:14 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:42:17,280 - olm-ocr-api - INFO - [2025-03-20 16:42:17] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=657857447, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 16:42:18,795 - olm-ocr-api - INFO - [2025-03-20 16:42:18] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 16:42:21,020 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:42:21,020 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:42:21,115 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 16:42:21,115 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 16:42:23,835 - olm-ocr-api - INFO - INFO 03-20 16:42:23 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:42:23,844 - olm-ocr-api - INFO - INFO 03-20 16:42:23 __init__.py:190] Automatically detected platform cuda.
2025-03-20 16:42:28,480 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 16:42:28,523 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 16:42:28,523 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 16:42:28,524 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Init torch distributed begin.
2025-03-20 16:42:28,682 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 16:42:28,682 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] Load weight begin. avail mem=30.84 GB
2025-03-20 16:42:28,777 - olm-ocr-api - INFO - [2025-03-20 16:42:28 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 16:42:29,057 - olm-ocr-api - INFO - [2025-03-20 16:42:29 TP0] Using model weights format ['*.safetensors']
2025-03-20 16:42:29,139 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 16:42:34,828 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:17,  5.69s/it]
2025-03-20 16:42:37,098 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:07<00:07,  3.68s/it]
2025-03-20 16:42:38,767 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:09<00:02,  2.76s/it]
2025-03-20 16:42:39,465 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:10<00:00,  1.95s/it]
2025-03-20 16:42:39,465 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:10<00:00,  2.58s/it]
2025-03-20 16:42:39,465 - olm-ocr-api - INFO - 
2025-03-20 16:42:39,879 - olm-ocr-api - INFO - [2025-03-20 16:42:39 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=15.12 GB, mem usage=15.72 GB.
2025-03-20 16:42:40,451 - olm-ocr-api - INFO - [2025-03-20 16:42:40 TP0] KV Cache is allocated. #tokens: 144533, K size: 3.86 GB, V size: 3.86 GB
2025-03-20 16:42:40,451 - olm-ocr-api - INFO - [2025-03-20 16:42:40 TP0] Memory pool end. avail mem=7.06 GB
2025-03-20 16:42:40,657 - olm-ocr-api - INFO - 2025-03-20 16:42:40,656 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 16:42:40,684 - olm-ocr-api - INFO - [2025-03-20 16:42:40 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.56 GB
2025-03-20 16:42:41,414 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 16:42:41,414 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 16:42:41,432 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - [2025-03-20 16:42:41 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2104, in _run_ninja_build
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -     subprocess.run(
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/subprocess.py", line 571, in run
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -     raise CalledProcessError(retcode, process.args,
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - The above exception was the direct cause of the following exception:
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,436 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 16:42:41,436 - olm-ocr-api - INFO -     self.capture()
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 16:42:41,437 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1833, in _write_ninja_file_and_build_library
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -     _run_ninja_build(
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2120, in _run_ninja_build
2025-03-20 16:42:41,438 - olm-ocr-api - INFO -     raise RuntimeError(message) from e
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - RuntimeError: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,438 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,439 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,440 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,440 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:42:41,440 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:42:41,440 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,490 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:42:41,491 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,491 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,491 - olm-ocr-api - INFO - During handling of the above exception, another exception occurred:
2025-03-20 16:42:41,491 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,491 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 16:42:41,491 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 254, in __init__
2025-03-20 16:42:41,492 - olm-ocr-api - INFO -     raise Exception(
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - Exception: Capture cuda graph failed: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,492 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,493 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,555 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/miniconda3/lib/python3.12/site-packages/torch/bin/nvcc: No such file or directory
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - Possible solutions:
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 1. disable cuda graph by --disable-cuda-graph
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 2. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 3. disable torch compile by not using --enable-torch-compile
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 4. set --cuda-graph-max-bs to a smaller value (e.g., 32)
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - 
2025-03-20 16:42:41,556 - olm-ocr-api - INFO - [2025-03-20 16:42:41] Received sigquit from a child process. It usually means the child failed.
2025-03-20 16:42:41,644 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 16:42:42,675 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 16:42:43,703 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 16:42:44,734 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 16:42:45,770 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 16:42:46,799 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 16:42:47,827 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 16:42:48,851 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 16:42:49,880 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 16:42:50,905 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 16:42:51,936 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 16:42:52,984 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 16:42:54,015 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 16:42:55,053 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 16:42:56,083 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 16:42:57,107 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 16:42:58,133 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 16:42:59,180 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 16:43:00,230 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 16:43:01,280 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 16:43:02,307 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 16:43:03,354 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 16:43:04,404 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 16:43:05,453 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 16:43:06,488 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 16:43:07,513 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 16:43:08,556 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 16:43:09,582 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 16:43:10,613 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 16:43:11,637 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 16:43:12,668 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 16:43:13,697 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 16:43:14,728 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 17:13:32,958 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:13:32,959 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:13:35,462 - olm-ocr-api - INFO - INFO 03-20 17:13:35 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:13:38,600 - olm-ocr-api - INFO - [2025-03-20 17:13:38] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=1021098257, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 17:13:40,166 - olm-ocr-api - INFO - [2025-03-20 17:13:40] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 17:13:41,859 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:13:41,859 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:13:41,900 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:13:41,900 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:13:44,567 - olm-ocr-api - INFO - INFO 03-20 17:13:44 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:13:44,619 - olm-ocr-api - INFO - INFO 03-20 17:13:44 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:13:48,193 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 17:13:48,236 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 17:13:48,236 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 17:13:48,237 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Init torch distributed begin.
2025-03-20 17:13:48,383 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 17:13:48,383 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Load weight begin. avail mem=30.84 GB
2025-03-20 17:13:48,486 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 17:13:48,773 - olm-ocr-api - INFO - [2025-03-20 17:13:48 TP0] Using model weights format ['*.safetensors']
2025-03-20 17:13:48,850 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 17:13:54,462 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:16,  5.61s/it]
2025-03-20 17:13:57,087 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:08<00:07,  3.86s/it]
2025-03-20 17:14:02,502 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:13<00:04,  4.57s/it]
2025-03-20 17:14:04,348 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.49s/it]
2025-03-20 17:14:04,348 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.87s/it]
2025-03-20 17:14:04,348 - olm-ocr-api - INFO - 
2025-03-20 17:14:04,407 - olm-ocr-api - INFO - [2025-03-20 17:14:04 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=15.12 GB, mem usage=15.72 GB.
2025-03-20 17:14:04,940 - olm-ocr-api - INFO - [2025-03-20 17:14:04 TP0] KV Cache is allocated. #tokens: 144533, K size: 3.86 GB, V size: 3.86 GB
2025-03-20 17:14:04,940 - olm-ocr-api - INFO - [2025-03-20 17:14:04 TP0] Memory pool end. avail mem=7.06 GB
2025-03-20 17:14:05,128 - olm-ocr-api - INFO - 2025-03-20 17:14:05,128 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 17:14:05,146 - olm-ocr-api - INFO - [2025-03-20 17:14:05 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.56 GB
2025-03-20 17:14:06,054 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 17:14:06,054 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 17:14:06,075 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - [2025-03-20 17:14:06 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2104, in _run_ninja_build
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -     subprocess.run(
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/subprocess.py", line 571, in run
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -     raise CalledProcessError(retcode, process.args,
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - The above exception was the direct cause of the following exception:
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,079 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -     self.capture()
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 17:14:06,079 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 17:14:06,080 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 17:14:06,081 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 17:14:06,081 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1833, in _write_ninja_file_and_build_library
2025-03-20 17:14:06,081 - olm-ocr-api - INFO -     _run_ninja_build(
2025-03-20 17:14:06,081 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2120, in _run_ninja_build
2025-03-20 17:14:06,081 - olm-ocr-api - INFO -     raise RuntimeError(message) from e
2025-03-20 17:14:06,081 - olm-ocr-api - INFO - RuntimeError: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,081 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,081 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,085 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,086 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,086 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,086 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,086 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,087 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:14:06,088 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,093 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,181 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,181 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - During handling of the above exception, another exception occurred:
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,182 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 17:14:06,182 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 17:14:06,183 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:14:06,183 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 254, in __init__
2025-03-20 17:14:06,183 - olm-ocr-api - INFO -     raise Exception(
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - Exception: Capture cuda graph failed: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:14:06,183 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - FAILED: batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - FAILED: batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,184 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/bin/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - /bin/sh: /local/home/hfurquan/myProjects/CUDA/bin/bin/nvcc: No such file or directory
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - Possible solutions:
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 1. disable cuda graph by --disable-cuda-graph
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 2. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 3. disable torch compile by not using --enable-torch-compile
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 4. set --cuda-graph-max-bs to a smaller value (e.g., 32)
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,275 - olm-ocr-api - INFO - 
2025-03-20 17:14:06,276 - olm-ocr-api - INFO - [2025-03-20 17:14:06] Received sigquit from a child process. It usually means the child failed.
2025-03-20 17:14:06,338 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 17:14:07,373 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 17:14:08,401 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 17:14:09,436 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 17:14:10,466 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 17:14:11,499 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 17:14:12,534 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 17:14:13,564 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 17:14:14,590 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 17:14:15,617 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 17:14:16,646 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 17:16:18,385 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:16:18,388 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:16:20,754 - olm-ocr-api - INFO - INFO 03-20 17:16:20 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:16:23,708 - olm-ocr-api - INFO - [2025-03-20 17:16:23] server_args=ServerArgs(model_path='allenai/olmOCR-7B-0225-preview', tokenizer_path='allenai/olmOCR-7B-0225-preview', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', trust_remote_code=False, dtype='auto', kv_cache_dtype='auto', quantization=None, quantization_param_path=None, context_length=None, device='cuda', served_model_name='allenai/olmOCR-7B-0225-preview', chat_template='qwen2-vl', is_embedding=False, revision=None, host='127.0.0.1', port=30024, mem_fraction_static=0.8, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, tp_size=1, stream_interval=1, stream_output=False, random_seed=426060385, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, log_level='info', log_level_http='warning', log_requests=False, log_requests_level=0, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, dp_size=1, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False, flashinfer_mla_disable_ragged=False, warmups=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False)
2025-03-20 17:16:25,272 - olm-ocr-api - INFO - [2025-03-20 17:16:25] Use chat template for the OpenAI-compatible API server: qwen2-vl
2025-03-20 17:16:26,968 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:16:26,968 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:16:26,974 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
2025-03-20 17:16:26,974 - olm-ocr-api - INFO -   warnings.warn(
2025-03-20 17:16:29,658 - olm-ocr-api - INFO - INFO 03-20 17:16:29 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:16:29,689 - olm-ocr-api - INFO - INFO 03-20 17:16:29 __init__.py:190] Automatically detected platform cuda.
2025-03-20 17:16:32,963 - olm-ocr-api - INFO - [2025-03-20 17:16:32 TP0] Overlap scheduler is disabled for multimodal models.
2025-03-20 17:16:33,003 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Automatically reduce --mem-fraction-static to 0.760 because this is a multimodal model.
2025-03-20 17:16:33,003 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Automatically turn off --chunked-prefill-size and disable radix cache for qwen2-vl.
2025-03-20 17:16:33,003 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Init torch distributed begin.
2025-03-20 17:16:33,152 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Init torch distributed ends. mem usage=0.00 GB
2025-03-20 17:16:33,152 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Load weight begin. avail mem=30.84 GB
2025-03-20 17:16:33,242 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] The following error message 'operation scheduled before its operands' can be ignored.
2025-03-20 17:16:33,491 - olm-ocr-api - INFO - [2025-03-20 17:16:33 TP0] Using model weights format ['*.safetensors']
2025-03-20 17:16:33,576 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
2025-03-20 17:16:34,801 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.22s/it]
2025-03-20 17:16:38,066 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:04<00:04,  2.42s/it]
2025-03-20 17:16:39,205 - olm-ocr-api - INFO - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:05<00:01,  1.84s/it]
2025-03-20 17:16:39,791 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.34s/it]
2025-03-20 17:16:39,791 - olm-ocr-api - INFO - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06<00:00,  1.55s/it]
2025-03-20 17:16:39,791 - olm-ocr-api - INFO - 
2025-03-20 17:16:39,891 - olm-ocr-api - INFO - [2025-03-20 17:16:39 TP0] Load weight end. type=Qwen2VLForConditionalGeneration, dtype=torch.bfloat16, avail mem=15.12 GB, mem usage=15.72 GB.
2025-03-20 17:16:40,350 - olm-ocr-api - INFO - [2025-03-20 17:16:40 TP0] KV Cache is allocated. #tokens: 144533, K size: 3.86 GB, V size: 3.86 GB
2025-03-20 17:16:40,350 - olm-ocr-api - INFO - [2025-03-20 17:16:40 TP0] Memory pool end. avail mem=7.06 GB
2025-03-20 17:16:40,500 - olm-ocr-api - INFO - 2025-03-20 17:16:40,500 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-20 17:16:40,520 - olm-ocr-api - INFO - [2025-03-20 17:16:40 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=6.56 GB
2025-03-20 17:16:41,196 - olm-ocr-api - INFO -   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:00<?, ?it/s]2025-03-20 17:16:41,195 - INFO - flashinfer.jit: Loading JIT ops: batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False
2025-03-20 17:16:54,082 - olm-ocr-api - INFO - Capturing batches (avail_mem=6.53 GB):   0%|          | 0/23 [00:13<?, ?it/s]
2025-03-20 17:16:54,085 - olm-ocr-api - INFO - [2025-03-20 17:16:54 TP0] Scheduler hit an exception: Traceback (most recent call last):
2025-03-20 17:16:54,085 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2104, in _run_ninja_build
2025-03-20 17:16:54,085 - olm-ocr-api - INFO -     subprocess.run(
2025-03-20 17:16:54,085 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/subprocess.py", line 571, in run
2025-03-20 17:16:54,085 - olm-ocr-api - INFO -     raise CalledProcessError(retcode, process.args,
2025-03-20 17:16:54,085 - olm-ocr-api - INFO - subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
2025-03-20 17:16:54,085 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,086 - olm-ocr-api - INFO - The above exception was the direct cause of the following exception:
2025-03-20 17:16:54,086 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,086 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 252, in __init__
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     self.capture()
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 336, in capture
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     ) = self.capture_one_batch_size(bs, forward)
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 406, in capture_one_batch_size
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     self.model_runner.attn_backend.init_forward_metadata_capture_cuda_graph(
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 303, in init_forward_metadata_capture_cuda_graph
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     self.indices_updater_decode.update(
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 553, in update_single_wrapper
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     self.call_begin_forward(
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/layers/attention/flashinfer_backend.py", line 663, in call_begin_forward
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     wrapper.begin_forward(
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/decode.py", line 867, in plan
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     self._cached_module = get_batch_prefill_module("fa2")(
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/prefill.py", line 197, in backend_module
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -     module = gen_batch_prefill_module(backend, *args)
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,086 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 568, in gen_batch_prefill_module
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     return gen_customize_batch_prefill_module(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/attention/pytorch.py", line 1012, in gen_customize_batch_prefill_module
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     return load_cuda_ops(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^^
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/jit/core.py", line 123, in load_cuda_ops
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     torch_cpp_ext.load(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1314, in load
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     return _jit_compile(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -            ^^^^^^^^^^^^^
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1721, in _jit_compile
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     _write_ninja_file_and_build_library(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 1833, in _write_ninja_file_and_build_library
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     _run_ninja_build(
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/utils/cpp_extension.py", line 2120, in _run_ninja_build
2025-03-20 17:16:54,087 - olm-ocr-api - INFO -     raise RuntimeError(message) from e
2025-03-20 17:16:54,087 - olm-ocr-api - INFO - RuntimeError: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,087 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,088 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,088 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu:17:
2025-03-20 17:16:54,088 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,088 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,088 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu:17:
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - fatal   : Could not open input file /tmp/tmpxft_0027b6f6_00000000-7_batch_prefill_jit_pybind.cpp1.ii
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu:22:
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,089 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,089 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu:22:
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,090 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - fatal   : Could not open input file /tmp/tmpxft_0027b6f5_00000000-7_batch_prefill.cpp1.ii
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:16:54,090 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - During handling of the above exception, another exception occurred:
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,093 - olm-ocr-api - INFO - Traceback (most recent call last):
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 1748, in run_scheduler_process
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -     scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, dp_rank)
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 218, in __init__
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -     self.tp_worker = TpWorkerClass(
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -                      ^^^^^^^^^^^^^^
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 74, in __init__
2025-03-20 17:16:54,093 - olm-ocr-api - INFO -     self.model_runner = ModelRunner(
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -                         ^^^^^^^^^^^^
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 166, in __init__
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -     self.initialize(min_per_gpu_memory)
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 207, in initialize
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -     self.init_cuda_graphs()
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 881, in init_cuda_graphs
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -     self.cuda_graph_runner = CudaGraphRunner(self)
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -                              ^^^^^^^^^^^^^^^^^^^^^
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -   File "/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 254, in __init__
2025-03-20 17:16:54,094 - olm-ocr-api - INFO -     raise Exception(
2025-03-20 17:16:54,094 - olm-ocr-api - INFO - Exception: Capture cuda graph failed: Error building extension 'batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False': [1/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,211 - olm-ocr-api - INFO - FAILED: batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,269 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_jit_pybind.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu -o batch_prefill_jit_pybind.cuda.o
2025-03-20 17:16:54,269 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu:17:
2025-03-20 17:16:54,269 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,269 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,269 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_jit_pybind.cu:17:
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - fatal   : Could not open input file /tmp/tmpxft_0027b6f6_00000000-7_batch_prefill_jit_pybind.cpp1.ii
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - [2/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - FAILED: batch_prefill.cuda.o
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu -o batch_prefill.cuda.o
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu:22:
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,270 - olm-ocr-api - INFO - In file included from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBase.h:14,
2025-03-20 17:16:54,270 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:38,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/jit_type.h:5,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/function_schema.h:6,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/ATen/core/op_registration/infer_schema.h:8,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/library.h:61,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc/pytorch_extension_utils.h:19,
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -                  from /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill.cu:22:
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/c10/util/C++17.h:13:2: error: #error "You're trying to build PyTorch with a too old version of GCC. We need GCC 9 or later."
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -  #error \
2025-03-20 17:16:54,271 - olm-ocr-api - INFO -   ^~~~~
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - fatal   : Could not open input file /tmp/tmpxft_0027b6f5_00000000-7_batch_prefill.cpp1.ii
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [3/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_0.cu -o batch_prefill_ragged_kernel_mask_0.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [4/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_1.cu -o batch_prefill_ragged_kernel_mask_1.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [5/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_0.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_0.cu -o batch_prefill_paged_kernel_mask_0.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [6/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_ragged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_ragged_kernel_mask_2.cu -o batch_prefill_ragged_kernel_mask_2.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [7/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_1.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_1.cu -o batch_prefill_paged_kernel_mask_1.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - [8/9] /local/home/hfurquan/myProjects/CUDA/bin/nvcc --generate-dependencies-with-compile --dependency-output batch_prefill_paged_kernel_mask_2.cuda.o.d -DTORCH_EXTENSION_NAME=batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/csrc -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/include -I/local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/flashinfer/data/cutlass/tools/util/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/TH -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/lib/python3.11/site-packages/torch/include/THC -isystem /local/home/hfurquan/myProjects/CUDA/include -isystem /local/home/hfurquan/miniconda3/envs/dialectic-bias/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 --expt-relaxed-constexpr -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -std=c++17 --threads 4 -use_fast_math -DFLASHINFER_ENABLE_F16 -DFLASHINFER_ENABLE_BF16 -DFLASHINFER_ENABLE_FP8_E4M3 -DFLASHINFER_ENABLE_FP8_E5M2 -c /cs/home/hfurquan/.cache/flashinfer/86/generated/batch_prefill_with_kv_cache_dtype_q_bf16_dtype_kv_bf16_dtype_o_bf16_dtype_idx_i32_head_dim_qk_128_head_dim_vo_128_posenc_0_use_swa_False_use_logits_cap_False_f16qk_False/batch_prefill_paged_kernel_mask_2.cu -o batch_prefill_paged_kernel_mask_2.cuda.o
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - ninja: build stopped: subcommand failed.
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - Possible solutions:
2025-03-20 17:16:54,271 - olm-ocr-api - INFO - 1. disable cuda graph by --disable-cuda-graph
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - 2. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - 3. disable torch compile by not using --enable-torch-compile
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - 4. set --cuda-graph-max-bs to a smaller value (e.g., 32)
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - 
2025-03-20 17:16:54,272 - olm-ocr-api - INFO - [2025-03-20 17:16:54] Received sigquit from a child process. It usually means the child failed.
2025-03-20 17:16:54,343 - olm-ocr-api - WARNING - Attempt 1: Please wait for sglang server to become ready...
2025-03-20 17:16:55,369 - olm-ocr-api - WARNING - Attempt 2: Please wait for sglang server to become ready...
2025-03-20 17:16:56,404 - olm-ocr-api - WARNING - Attempt 3: Please wait for sglang server to become ready...
2025-03-20 17:16:57,431 - olm-ocr-api - WARNING - Attempt 4: Please wait for sglang server to become ready...
2025-03-20 17:16:58,458 - olm-ocr-api - WARNING - Attempt 5: Please wait for sglang server to become ready...
2025-03-20 17:16:59,482 - olm-ocr-api - WARNING - Attempt 6: Please wait for sglang server to become ready...
2025-03-20 17:17:00,510 - olm-ocr-api - WARNING - Attempt 7: Please wait for sglang server to become ready...
2025-03-20 17:17:01,538 - olm-ocr-api - WARNING - Attempt 8: Please wait for sglang server to become ready...
2025-03-20 17:17:02,568 - olm-ocr-api - WARNING - Attempt 9: Please wait for sglang server to become ready...
2025-03-20 17:17:03,600 - olm-ocr-api - WARNING - Attempt 10: Please wait for sglang server to become ready...
2025-03-20 17:17:04,628 - olm-ocr-api - WARNING - Attempt 11: Please wait for sglang server to become ready...
2025-03-20 17:17:05,662 - olm-ocr-api - WARNING - Attempt 12: Please wait for sglang server to become ready...
2025-03-20 17:17:06,692 - olm-ocr-api - WARNING - Attempt 13: Please wait for sglang server to become ready...
2025-03-20 17:17:07,720 - olm-ocr-api - WARNING - Attempt 14: Please wait for sglang server to become ready...
2025-03-20 17:17:08,751 - olm-ocr-api - WARNING - Attempt 15: Please wait for sglang server to become ready...
2025-03-20 17:17:09,804 - olm-ocr-api - WARNING - Attempt 16: Please wait for sglang server to become ready...
2025-03-20 17:17:10,847 - olm-ocr-api - WARNING - Attempt 17: Please wait for sglang server to become ready...
2025-03-20 17:17:11,882 - olm-ocr-api - WARNING - Attempt 18: Please wait for sglang server to become ready...
2025-03-20 17:17:12,912 - olm-ocr-api - WARNING - Attempt 19: Please wait for sglang server to become ready...
2025-03-20 17:17:13,940 - olm-ocr-api - WARNING - Attempt 20: Please wait for sglang server to become ready...
2025-03-20 17:17:14,966 - olm-ocr-api - WARNING - Attempt 21: Please wait for sglang server to become ready...
2025-03-20 17:17:16,002 - olm-ocr-api - WARNING - Attempt 22: Please wait for sglang server to become ready...
2025-03-20 17:17:17,049 - olm-ocr-api - WARNING - Attempt 23: Please wait for sglang server to become ready...
2025-03-20 17:17:18,098 - olm-ocr-api - WARNING - Attempt 24: Please wait for sglang server to become ready...
2025-03-20 17:17:19,125 - olm-ocr-api - WARNING - Attempt 25: Please wait for sglang server to become ready...
2025-03-20 17:17:20,158 - olm-ocr-api - WARNING - Attempt 26: Please wait for sglang server to become ready...
2025-03-20 17:17:21,186 - olm-ocr-api - WARNING - Attempt 27: Please wait for sglang server to become ready...
2025-03-20 17:17:22,215 - olm-ocr-api - WARNING - Attempt 28: Please wait for sglang server to become ready...
2025-03-20 17:17:23,241 - olm-ocr-api - WARNING - Attempt 29: Please wait for sglang server to become ready...
2025-03-20 17:17:24,267 - olm-ocr-api - WARNING - Attempt 30: Please wait for sglang server to become ready...
2025-03-20 17:17:25,320 - olm-ocr-api - WARNING - Attempt 31: Please wait for sglang server to become ready...
2025-03-20 17:17:26,354 - olm-ocr-api - WARNING - Attempt 32: Please wait for sglang server to become ready...
2025-03-20 17:17:27,380 - olm-ocr-api - WARNING - Attempt 33: Please wait for sglang server to become ready...
2025-03-20 17:17:28,409 - olm-ocr-api - WARNING - Attempt 34: Please wait for sglang server to become ready...
2025-03-20 17:17:29,468 - olm-ocr-api - WARNING - Attempt 35: Please wait for sglang server to become ready...
2025-03-20 17:17:30,498 - olm-ocr-api - WARNING - Attempt 36: Please wait for sglang server to become ready...
2025-03-20 17:17:31,532 - olm-ocr-api - WARNING - Attempt 37: Please wait for sglang server to become ready...
2025-03-20 17:17:32,559 - olm-ocr-api - WARNING - Attempt 38: Please wait for sglang server to become ready...
2025-03-20 17:17:33,606 - olm-ocr-api - WARNING - Attempt 39: Please wait for sglang server to become ready...
2025-03-20 17:17:34,637 - olm-ocr-api - WARNING - Attempt 40: Please wait for sglang server to become ready...
2025-03-20 17:17:35,691 - olm-ocr-api - WARNING - Attempt 41: Please wait for sglang server to become ready...
2025-03-20 17:17:36,740 - olm-ocr-api - WARNING - Attempt 42: Please wait for sglang server to become ready...
2025-03-20 17:17:37,790 - olm-ocr-api - WARNING - Attempt 43: Please wait for sglang server to become ready...
2025-03-20 17:17:38,819 - olm-ocr-api - WARNING - Attempt 44: Please wait for sglang server to become ready...
2025-03-20 17:17:39,846 - olm-ocr-api - WARNING - Attempt 45: Please wait for sglang server to become ready...
2025-03-20 17:17:40,874 - olm-ocr-api - WARNING - Attempt 46: Please wait for sglang server to become ready...
2025-03-20 17:17:41,907 - olm-ocr-api - WARNING - Attempt 47: Please wait for sglang server to become ready...
2025-03-20 17:17:42,933 - olm-ocr-api - WARNING - Attempt 48: Please wait for sglang server to become ready...
2025-03-20 17:17:43,985 - olm-ocr-api - WARNING - Attempt 49: Please wait for sglang server to become ready...
